{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QinQipeng/COMP4436-IoT-Project/blob/main/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRm-USlsHgEV",
        "outputId": "95c4d197-aa38-4f1e-9138-19e48c8ae455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2516, done.\u001b[K\n",
            "remote: Total 2516 (delta 0), reused 0 (delta 0), pack-reused 2516 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2516/2516), 8.20 MiB | 11.66 MiB/s, done.\n",
            "Resolving deltas: 100% (1575/1575), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1EySlOXwwoa",
        "outputId": "92be0495-4ab1-47b2-b65b-cc37dfddb2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.19.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.33)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=cec851801793efba44e322d1f490d6ceddaa075b4be4043037de638c672b74a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/a4/bb/2be445c295d88a74f9c0a4232f04860ca489a5c7c57eb959d9\n",
            "Successfully built visdom\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dominate, visdom, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dominate-2.9.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 visdom-0.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daqlgVhw29P"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "Download one of the official datasets with:\n",
        "\n",
        "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n",
        "\n",
        "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrdOettJxaCc",
        "outputId": "3f928d1d-74b1-41a4-ad03-51eac7dd514b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specified [facades]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2025-05-03 08:39:15--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30168306 (29M) [application/x-gzip]\n",
            "Saving to: ‘./datasets/facades.tar.gz’\n",
            "\n",
            "./datasets/facades. 100%[===================>]  28.77M  3.35MB/s    in 9.0s    \n",
            "\n",
            "2025-05-03 08:39:24 (3.21 MB/s) - ‘./datasets/facades.tar.gz’ saved [30168306/30168306]\n",
            "\n",
            "facades/\n",
            "facades/test/\n",
            "facades/test/27.jpg\n",
            "facades/test/5.jpg\n",
            "facades/test/72.jpg\n",
            "facades/test/1.jpg\n",
            "facades/test/10.jpg\n",
            "facades/test/100.jpg\n",
            "facades/test/101.jpg\n",
            "facades/test/102.jpg\n",
            "facades/test/103.jpg\n",
            "facades/test/104.jpg\n",
            "facades/test/105.jpg\n",
            "facades/test/106.jpg\n",
            "facades/test/11.jpg\n",
            "facades/test/12.jpg\n",
            "facades/test/13.jpg\n",
            "facades/test/14.jpg\n",
            "facades/test/15.jpg\n",
            "facades/test/16.jpg\n",
            "facades/test/17.jpg\n",
            "facades/test/18.jpg\n",
            "facades/test/19.jpg\n",
            "facades/test/2.jpg\n",
            "facades/test/20.jpg\n",
            "facades/test/21.jpg\n",
            "facades/test/22.jpg\n",
            "facades/test/23.jpg\n",
            "facades/test/24.jpg\n",
            "facades/test/25.jpg\n",
            "facades/test/26.jpg\n",
            "facades/test/50.jpg\n",
            "facades/test/51.jpg\n",
            "facades/test/52.jpg\n",
            "facades/test/53.jpg\n",
            "facades/test/54.jpg\n",
            "facades/test/55.jpg\n",
            "facades/test/56.jpg\n",
            "facades/test/57.jpg\n",
            "facades/test/58.jpg\n",
            "facades/test/59.jpg\n",
            "facades/test/6.jpg\n",
            "facades/test/60.jpg\n",
            "facades/test/61.jpg\n",
            "facades/test/62.jpg\n",
            "facades/test/63.jpg\n",
            "facades/test/64.jpg\n",
            "facades/test/65.jpg\n",
            "facades/test/66.jpg\n",
            "facades/test/67.jpg\n",
            "facades/test/68.jpg\n",
            "facades/test/69.jpg\n",
            "facades/test/7.jpg\n",
            "facades/test/70.jpg\n",
            "facades/test/71.jpg\n",
            "facades/test/73.jpg\n",
            "facades/test/74.jpg\n",
            "facades/test/75.jpg\n",
            "facades/test/76.jpg\n",
            "facades/test/77.jpg\n",
            "facades/test/78.jpg\n",
            "facades/test/79.jpg\n",
            "facades/test/8.jpg\n",
            "facades/test/80.jpg\n",
            "facades/test/81.jpg\n",
            "facades/test/82.jpg\n",
            "facades/test/83.jpg\n",
            "facades/test/84.jpg\n",
            "facades/test/85.jpg\n",
            "facades/test/86.jpg\n",
            "facades/test/87.jpg\n",
            "facades/test/88.jpg\n",
            "facades/test/89.jpg\n",
            "facades/test/9.jpg\n",
            "facades/test/90.jpg\n",
            "facades/test/91.jpg\n",
            "facades/test/92.jpg\n",
            "facades/test/93.jpg\n",
            "facades/test/94.jpg\n",
            "facades/test/95.jpg\n",
            "facades/test/96.jpg\n",
            "facades/test/97.jpg\n",
            "facades/test/98.jpg\n",
            "facades/test/99.jpg\n",
            "facades/test/28.jpg\n",
            "facades/test/29.jpg\n",
            "facades/test/3.jpg\n",
            "facades/test/30.jpg\n",
            "facades/test/31.jpg\n",
            "facades/test/32.jpg\n",
            "facades/test/33.jpg\n",
            "facades/test/34.jpg\n",
            "facades/test/35.jpg\n",
            "facades/test/36.jpg\n",
            "facades/test/37.jpg\n",
            "facades/test/38.jpg\n",
            "facades/test/39.jpg\n",
            "facades/test/4.jpg\n",
            "facades/test/40.jpg\n",
            "facades/test/41.jpg\n",
            "facades/test/42.jpg\n",
            "facades/test/43.jpg\n",
            "facades/test/44.jpg\n",
            "facades/test/45.jpg\n",
            "facades/test/46.jpg\n",
            "facades/test/47.jpg\n",
            "facades/test/48.jpg\n",
            "facades/test/49.jpg\n",
            "facades/train/\n",
            "facades/train/1.jpg\n",
            "facades/train/10.jpg\n",
            "facades/train/100.jpg\n",
            "facades/train/101.jpg\n",
            "facades/train/102.jpg\n",
            "facades/train/103.jpg\n",
            "facades/train/104.jpg\n",
            "facades/train/105.jpg\n",
            "facades/train/106.jpg\n",
            "facades/train/107.jpg\n",
            "facades/train/108.jpg\n",
            "facades/train/109.jpg\n",
            "facades/train/11.jpg\n",
            "facades/train/110.jpg\n",
            "facades/train/111.jpg\n",
            "facades/train/112.jpg\n",
            "facades/train/113.jpg\n",
            "facades/train/114.jpg\n",
            "facades/train/115.jpg\n",
            "facades/train/116.jpg\n",
            "facades/train/117.jpg\n",
            "facades/train/118.jpg\n",
            "facades/train/119.jpg\n",
            "facades/train/12.jpg\n",
            "facades/train/120.jpg\n",
            "facades/train/121.jpg\n",
            "facades/train/122.jpg\n",
            "facades/train/123.jpg\n",
            "facades/train/124.jpg\n",
            "facades/train/125.jpg\n",
            "facades/train/126.jpg\n",
            "facades/train/309.jpg\n",
            "facades/train/31.jpg\n",
            "facades/train/310.jpg\n",
            "facades/train/311.jpg\n",
            "facades/train/312.jpg\n",
            "facades/train/313.jpg\n",
            "facades/train/314.jpg\n",
            "facades/train/315.jpg\n",
            "facades/train/316.jpg\n",
            "facades/train/317.jpg\n",
            "facades/train/318.jpg\n",
            "facades/train/319.jpg\n",
            "facades/train/32.jpg\n",
            "facades/train/320.jpg\n",
            "facades/train/321.jpg\n",
            "facades/train/322.jpg\n",
            "facades/train/323.jpg\n",
            "facades/train/324.jpg\n",
            "facades/train/325.jpg\n",
            "facades/train/326.jpg\n",
            "facades/train/327.jpg\n",
            "facades/train/328.jpg\n",
            "facades/train/329.jpg\n",
            "facades/train/390.jpg\n",
            "facades/train/391.jpg\n",
            "facades/train/392.jpg\n",
            "facades/train/393.jpg\n",
            "facades/train/394.jpg\n",
            "facades/train/395.jpg\n",
            "facades/train/396.jpg\n",
            "facades/train/397.jpg\n",
            "facades/train/398.jpg\n",
            "facades/train/399.jpg\n",
            "facades/train/4.jpg\n",
            "facades/train/40.jpg\n",
            "facades/train/400.jpg\n",
            "facades/train/41.jpg\n",
            "facades/train/42.jpg\n",
            "facades/train/43.jpg\n",
            "facades/train/44.jpg\n",
            "facades/train/45.jpg\n",
            "facades/train/46.jpg\n",
            "facades/train/47.jpg\n",
            "facades/train/48.jpg\n",
            "facades/train/49.jpg\n",
            "facades/train/5.jpg\n",
            "facades/train/50.jpg\n",
            "facades/train/51.jpg\n",
            "facades/train/52.jpg\n",
            "facades/train/53.jpg\n",
            "facades/train/54.jpg\n",
            "facades/train/55.jpg\n",
            "facades/train/56.jpg\n",
            "facades/train/57.jpg\n",
            "facades/train/58.jpg\n",
            "facades/train/59.jpg\n",
            "facades/train/6.jpg\n",
            "facades/train/60.jpg\n",
            "facades/train/61.jpg\n",
            "facades/train/222.jpg\n",
            "facades/train/223.jpg\n",
            "facades/train/224.jpg\n",
            "facades/train/225.jpg\n",
            "facades/train/226.jpg\n",
            "facades/train/227.jpg\n",
            "facades/train/228.jpg\n",
            "facades/train/229.jpg\n",
            "facades/train/23.jpg\n",
            "facades/train/230.jpg\n",
            "facades/train/231.jpg\n",
            "facades/train/232.jpg\n",
            "facades/train/233.jpg\n",
            "facades/train/234.jpg\n",
            "facades/train/235.jpg\n",
            "facades/train/236.jpg\n",
            "facades/train/237.jpg\n",
            "facades/train/238.jpg\n",
            "facades/train/239.jpg\n",
            "facades/train/24.jpg\n",
            "facades/train/240.jpg\n",
            "facades/train/241.jpg\n",
            "facades/train/242.jpg\n",
            "facades/train/243.jpg\n",
            "facades/train/244.jpg\n",
            "facades/train/245.jpg\n",
            "facades/train/156.jpg\n",
            "facades/train/157.jpg\n",
            "facades/train/158.jpg\n",
            "facades/train/159.jpg\n",
            "facades/train/16.jpg\n",
            "facades/train/160.jpg\n",
            "facades/train/161.jpg\n",
            "facades/train/162.jpg\n",
            "facades/train/163.jpg\n",
            "facades/train/164.jpg\n",
            "facades/train/165.jpg\n",
            "facades/train/166.jpg\n",
            "facades/train/167.jpg\n",
            "facades/train/168.jpg\n",
            "facades/train/169.jpg\n",
            "facades/train/17.jpg\n",
            "facades/train/170.jpg\n",
            "facades/train/171.jpg\n",
            "facades/train/172.jpg\n",
            "facades/train/173.jpg\n",
            "facades/train/174.jpg\n",
            "facades/train/175.jpg\n",
            "facades/train/176.jpg\n",
            "facades/train/177.jpg\n",
            "facades/train/178.jpg\n",
            "facades/train/179.jpg\n",
            "facades/train/18.jpg\n",
            "facades/train/180.jpg\n",
            "facades/train/181.jpg\n",
            "facades/train/182.jpg\n",
            "facades/train/183.jpg\n",
            "facades/train/184.jpg\n",
            "facades/train/185.jpg\n",
            "facades/train/186.jpg\n",
            "facades/train/187.jpg\n",
            "facades/train/188.jpg\n",
            "facades/train/189.jpg\n",
            "facades/train/19.jpg\n",
            "facades/train/127.jpg\n",
            "facades/train/155.jpg\n",
            "facades/train/190.jpg\n",
            "facades/train/221.jpg\n",
            "facades/train/246.jpg\n",
            "facades/train/27.jpg\n",
            "facades/train/29.jpg\n",
            "facades/train/308.jpg\n",
            "facades/train/33.jpg\n",
            "facades/train/350.jpg\n",
            "facades/train/370.jpg\n",
            "facades/train/39.jpg\n",
            "facades/train/62.jpg\n",
            "facades/train/270.jpg\n",
            "facades/train/271.jpg\n",
            "facades/train/272.jpg\n",
            "facades/train/273.jpg\n",
            "facades/train/274.jpg\n",
            "facades/train/275.jpg\n",
            "facades/train/276.jpg\n",
            "facades/train/277.jpg\n",
            "facades/train/278.jpg\n",
            "facades/train/279.jpg\n",
            "facades/train/28.jpg\n",
            "facades/train/280.jpg\n",
            "facades/train/281.jpg\n",
            "facades/train/282.jpg\n",
            "facades/train/283.jpg\n",
            "facades/train/284.jpg\n",
            "facades/train/285.jpg\n",
            "facades/train/286.jpg\n",
            "facades/train/287.jpg\n",
            "facades/train/288.jpg\n",
            "facades/train/289.jpg\n",
            "facades/train/351.jpg\n",
            "facades/train/352.jpg\n",
            "facades/train/353.jpg\n",
            "facades/train/354.jpg\n",
            "facades/train/355.jpg\n",
            "facades/train/356.jpg\n",
            "facades/train/357.jpg\n",
            "facades/train/358.jpg\n",
            "facades/train/359.jpg\n",
            "facades/train/36.jpg\n",
            "facades/train/360.jpg\n",
            "facades/train/361.jpg\n",
            "facades/train/362.jpg\n",
            "facades/train/363.jpg\n",
            "facades/train/364.jpg\n",
            "facades/train/365.jpg\n",
            "facades/train/366.jpg\n",
            "facades/train/367.jpg\n",
            "facades/train/368.jpg\n",
            "facades/train/369.jpg\n",
            "facades/train/37.jpg\n",
            "facades/train/63.jpg\n",
            "facades/train/64.jpg\n",
            "facades/train/65.jpg\n",
            "facades/train/66.jpg\n",
            "facades/train/67.jpg\n",
            "facades/train/68.jpg\n",
            "facades/train/69.jpg\n",
            "facades/train/7.jpg\n",
            "facades/train/70.jpg\n",
            "facades/train/71.jpg\n",
            "facades/train/72.jpg\n",
            "facades/train/73.jpg\n",
            "facades/train/74.jpg\n",
            "facades/train/75.jpg\n",
            "facades/train/76.jpg\n",
            "facades/train/77.jpg\n",
            "facades/train/78.jpg\n",
            "facades/train/79.jpg\n",
            "facades/train/8.jpg\n",
            "facades/train/80.jpg\n",
            "facades/train/81.jpg\n",
            "facades/train/82.jpg\n",
            "facades/train/83.jpg\n",
            "facades/train/84.jpg\n",
            "facades/train/85.jpg\n",
            "facades/train/86.jpg\n",
            "facades/train/87.jpg\n",
            "facades/train/88.jpg\n",
            "facades/train/89.jpg\n",
            "facades/train/9.jpg\n",
            "facades/train/90.jpg\n",
            "facades/train/91.jpg\n",
            "facades/train/92.jpg\n",
            "facades/train/93.jpg\n",
            "facades/train/94.jpg\n",
            "facades/train/95.jpg\n",
            "facades/train/96.jpg\n",
            "facades/train/97.jpg\n",
            "facades/train/98.jpg\n",
            "facades/train/99.jpg\n",
            "facades/train/128.jpg\n",
            "facades/train/129.jpg\n",
            "facades/train/13.jpg\n",
            "facades/train/130.jpg\n",
            "facades/train/131.jpg\n",
            "facades/train/132.jpg\n",
            "facades/train/133.jpg\n",
            "facades/train/134.jpg\n",
            "facades/train/135.jpg\n",
            "facades/train/136.jpg\n",
            "facades/train/137.jpg\n",
            "facades/train/138.jpg\n",
            "facades/train/139.jpg\n",
            "facades/train/14.jpg\n",
            "facades/train/140.jpg\n",
            "facades/train/141.jpg\n",
            "facades/train/142.jpg\n",
            "facades/train/143.jpg\n",
            "facades/train/144.jpg\n",
            "facades/train/145.jpg\n",
            "facades/train/146.jpg\n",
            "facades/train/147.jpg\n",
            "facades/train/148.jpg\n",
            "facades/train/149.jpg\n",
            "facades/train/15.jpg\n",
            "facades/train/150.jpg\n",
            "facades/train/151.jpg\n",
            "facades/train/152.jpg\n",
            "facades/train/153.jpg\n",
            "facades/train/154.jpg\n",
            "facades/train/191.jpg\n",
            "facades/train/192.jpg\n",
            "facades/train/193.jpg\n",
            "facades/train/194.jpg\n",
            "facades/train/195.jpg\n",
            "facades/train/196.jpg\n",
            "facades/train/197.jpg\n",
            "facades/train/198.jpg\n",
            "facades/train/199.jpg\n",
            "facades/train/2.jpg\n",
            "facades/train/20.jpg\n",
            "facades/train/200.jpg\n",
            "facades/train/201.jpg\n",
            "facades/train/202.jpg\n",
            "facades/train/203.jpg\n",
            "facades/train/204.jpg\n",
            "facades/train/205.jpg\n",
            "facades/train/206.jpg\n",
            "facades/train/207.jpg\n",
            "facades/train/208.jpg\n",
            "facades/train/209.jpg\n",
            "facades/train/21.jpg\n",
            "facades/train/210.jpg\n",
            "facades/train/211.jpg\n",
            "facades/train/212.jpg\n",
            "facades/train/213.jpg\n",
            "facades/train/214.jpg\n",
            "facades/train/215.jpg\n",
            "facades/train/216.jpg\n",
            "facades/train/217.jpg\n",
            "facades/train/218.jpg\n",
            "facades/train/219.jpg\n",
            "facades/train/22.jpg\n",
            "facades/train/220.jpg\n",
            "facades/train/247.jpg\n",
            "facades/train/248.jpg\n",
            "facades/train/249.jpg\n",
            "facades/train/25.jpg\n",
            "facades/train/250.jpg\n",
            "facades/train/251.jpg\n",
            "facades/train/252.jpg\n",
            "facades/train/253.jpg\n",
            "facades/train/254.jpg\n",
            "facades/train/255.jpg\n",
            "facades/train/256.jpg\n",
            "facades/train/257.jpg\n",
            "facades/train/258.jpg\n",
            "facades/train/259.jpg\n",
            "facades/train/26.jpg\n",
            "facades/train/260.jpg\n",
            "facades/train/261.jpg\n",
            "facades/train/262.jpg\n",
            "facades/train/263.jpg\n",
            "facades/train/264.jpg\n",
            "facades/train/265.jpg\n",
            "facades/train/266.jpg\n",
            "facades/train/267.jpg\n",
            "facades/train/268.jpg\n",
            "facades/train/269.jpg\n",
            "facades/train/330.jpg\n",
            "facades/train/331.jpg\n",
            "facades/train/332.jpg\n",
            "facades/train/333.jpg\n",
            "facades/train/334.jpg\n",
            "facades/train/335.jpg\n",
            "facades/train/336.jpg\n",
            "facades/train/337.jpg\n",
            "facades/train/338.jpg\n",
            "facades/train/339.jpg\n",
            "facades/train/34.jpg\n",
            "facades/train/340.jpg\n",
            "facades/train/341.jpg\n",
            "facades/train/342.jpg\n",
            "facades/train/343.jpg\n",
            "facades/train/344.jpg\n",
            "facades/train/345.jpg\n",
            "facades/train/346.jpg\n",
            "facades/train/347.jpg\n",
            "facades/train/348.jpg\n",
            "facades/train/349.jpg\n",
            "facades/train/35.jpg\n",
            "facades/train/290.jpg\n",
            "facades/train/291.jpg\n",
            "facades/train/292.jpg\n",
            "facades/train/293.jpg\n",
            "facades/train/294.jpg\n",
            "facades/train/295.jpg\n",
            "facades/train/296.jpg\n",
            "facades/train/297.jpg\n",
            "facades/train/298.jpg\n",
            "facades/train/299.jpg\n",
            "facades/train/3.jpg\n",
            "facades/train/30.jpg\n",
            "facades/train/300.jpg\n",
            "facades/train/301.jpg\n",
            "facades/train/302.jpg\n",
            "facades/train/303.jpg\n",
            "facades/train/304.jpg\n",
            "facades/train/305.jpg\n",
            "facades/train/306.jpg\n",
            "facades/train/307.jpg\n",
            "facades/train/371.jpg\n",
            "facades/train/372.jpg\n",
            "facades/train/373.jpg\n",
            "facades/train/374.jpg\n",
            "facades/train/375.jpg\n",
            "facades/train/376.jpg\n",
            "facades/train/377.jpg\n",
            "facades/train/378.jpg\n",
            "facades/train/379.jpg\n",
            "facades/train/38.jpg\n",
            "facades/train/380.jpg\n",
            "facades/train/381.jpg\n",
            "facades/train/382.jpg\n",
            "facades/train/383.jpg\n",
            "facades/train/384.jpg\n",
            "facades/train/385.jpg\n",
            "facades/train/386.jpg\n",
            "facades/train/387.jpg\n",
            "facades/train/388.jpg\n",
            "facades/train/389.jpg\n",
            "facades/val/\n",
            "facades/val/30.jpg\n",
            "facades/val/50.jpg\n",
            "facades/val/73.jpg\n",
            "facades/val/1.jpg\n",
            "facades/val/10.jpg\n",
            "facades/val/100.jpg\n",
            "facades/val/11.jpg\n",
            "facades/val/12.jpg\n",
            "facades/val/13.jpg\n",
            "facades/val/14.jpg\n",
            "facades/val/15.jpg\n",
            "facades/val/16.jpg\n",
            "facades/val/17.jpg\n",
            "facades/val/18.jpg\n",
            "facades/val/19.jpg\n",
            "facades/val/2.jpg\n",
            "facades/val/20.jpg\n",
            "facades/val/21.jpg\n",
            "facades/val/22.jpg\n",
            "facades/val/23.jpg\n",
            "facades/val/24.jpg\n",
            "facades/val/25.jpg\n",
            "facades/val/26.jpg\n",
            "facades/val/27.jpg\n",
            "facades/val/28.jpg\n",
            "facades/val/29.jpg\n",
            "facades/val/3.jpg\n",
            "facades/val/51.jpg\n",
            "facades/val/52.jpg\n",
            "facades/val/53.jpg\n",
            "facades/val/54.jpg\n",
            "facades/val/55.jpg\n",
            "facades/val/56.jpg\n",
            "facades/val/57.jpg\n",
            "facades/val/58.jpg\n",
            "facades/val/59.jpg\n",
            "facades/val/6.jpg\n",
            "facades/val/60.jpg\n",
            "facades/val/61.jpg\n",
            "facades/val/62.jpg\n",
            "facades/val/63.jpg\n",
            "facades/val/64.jpg\n",
            "facades/val/65.jpg\n",
            "facades/val/66.jpg\n",
            "facades/val/67.jpg\n",
            "facades/val/68.jpg\n",
            "facades/val/69.jpg\n",
            "facades/val/7.jpg\n",
            "facades/val/70.jpg\n",
            "facades/val/71.jpg\n",
            "facades/val/72.jpg\n",
            "facades/val/74.jpg\n",
            "facades/val/75.jpg\n",
            "facades/val/76.jpg\n",
            "facades/val/77.jpg\n",
            "facades/val/78.jpg\n",
            "facades/val/79.jpg\n",
            "facades/val/8.jpg\n",
            "facades/val/80.jpg\n",
            "facades/val/81.jpg\n",
            "facades/val/82.jpg\n",
            "facades/val/83.jpg\n",
            "facades/val/84.jpg\n",
            "facades/val/85.jpg\n",
            "facades/val/86.jpg\n",
            "facades/val/87.jpg\n",
            "facades/val/88.jpg\n",
            "facades/val/89.jpg\n",
            "facades/val/9.jpg\n",
            "facades/val/90.jpg\n",
            "facades/val/91.jpg\n",
            "facades/val/92.jpg\n",
            "facades/val/93.jpg\n",
            "facades/val/94.jpg\n",
            "facades/val/95.jpg\n",
            "facades/val/96.jpg\n",
            "facades/val/97.jpg\n",
            "facades/val/98.jpg\n",
            "facades/val/99.jpg\n",
            "facades/val/31.jpg\n",
            "facades/val/32.jpg\n",
            "facades/val/33.jpg\n",
            "facades/val/34.jpg\n",
            "facades/val/35.jpg\n",
            "facades/val/36.jpg\n",
            "facades/val/37.jpg\n",
            "facades/val/38.jpg\n",
            "facades/val/39.jpg\n",
            "facades/val/4.jpg\n",
            "facades/val/40.jpg\n",
            "facades/val/41.jpg\n",
            "facades/val/42.jpg\n",
            "facades/val/43.jpg\n",
            "facades/val/44.jpg\n",
            "facades/val/45.jpg\n",
            "facades/val/46.jpg\n",
            "facades/val/47.jpg\n",
            "facades/val/48.jpg\n",
            "facades/val/49.jpg\n",
            "facades/val/5.jpg\n"
          ]
        }
      ],
      "source": [
        "!bash ./datasets/download_pix2pix_dataset.sh facades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdUz4116xhpm"
      },
      "source": [
        "# Pretrained models\n",
        "\n",
        "Download one of the official pretrained models with:\n",
        "\n",
        "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
        "\n",
        "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC2DEP4M0OsS",
        "outputId": "2b607236-e55e-4d95-9e3e-9603f721177a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\n",
            "Specified [facades_label2photo]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2025-05-03 08:39:53--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/facades_label2photo.pth\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217704720 (208M)\n",
            "Saving to: ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’\n",
            "\n",
            "./checkpoints/facad 100%[===================>] 207.62M  65.3MB/s    in 3.3s    \n",
            "\n",
            "2025-05-03 08:39:57 (63.5 MB/s) - ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’ saved [217704720/217704720]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!bash ./scripts/download_pix2pix_model.sh facades_label2photo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sp7TCT2x9dB",
        "outputId": "61b2a6ac-575f-4cd3-9be8-41f1fa456669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/facades            \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: BtoA                          \t[default: AtoB]\n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: vanilla                       \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: cycle_gan]\n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: facades_pix2pix               \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: batch                         \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "The number of training images = 400\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.414 M\n",
            "[Network D] Total number of parameters : 2.769 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/facades_pix2pix/web...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.088, data: 0.223) G_GAN: 2.661 G_L1: 33.413 D_real: 0.362 D_fake: 0.130 \n",
            "(epoch: 1, iters: 200, time: 0.090, data: 0.002) G_GAN: 2.153 G_L1: 30.594 D_real: 0.291 D_fake: 0.330 \n",
            "(epoch: 1, iters: 300, time: 0.075, data: 0.002) G_GAN: 3.038 G_L1: 28.429 D_real: 0.029 D_fake: 0.239 \n",
            "(epoch: 1, iters: 400, time: 0.157, data: 0.002) G_GAN: 1.423 G_L1: 36.700 D_real: 2.460 D_fake: 0.031 \n",
            "End of epoch 1 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.075, data: 0.108) G_GAN: 1.838 G_L1: 27.226 D_real: 0.024 D_fake: 0.482 \n",
            "(epoch: 2, iters: 200, time: 0.089, data: 0.009) G_GAN: 3.013 G_L1: 38.854 D_real: 0.101 D_fake: 0.160 \n",
            "(epoch: 2, iters: 300, time: 0.088, data: 0.002) G_GAN: 3.334 G_L1: 55.158 D_real: 0.028 D_fake: 0.071 \n",
            "(epoch: 2, iters: 400, time: 0.170, data: 0.002) G_GAN: 4.147 G_L1: 36.026 D_real: 0.207 D_fake: 0.022 \n",
            "End of epoch 2 / 200 \t Time Taken: 21 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.091, data: 0.126) G_GAN: 2.423 G_L1: 35.599 D_real: 0.210 D_fake: 0.049 \n",
            "(epoch: 3, iters: 200, time: 0.092, data: 0.002) G_GAN: 4.072 G_L1: 34.984 D_real: 0.257 D_fake: 0.019 \n",
            "(epoch: 3, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.803 G_L1: 34.481 D_real: 0.182 D_fake: 0.054 \n",
            "(epoch: 3, iters: 400, time: 0.167, data: 0.002) G_GAN: 2.228 G_L1: 49.351 D_real: 0.003 D_fake: 0.223 \n",
            "End of epoch 3 / 200 \t Time Taken: 21 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.092, data: 0.237) G_GAN: 2.605 G_L1: 36.589 D_real: 0.011 D_fake: 0.126 \n",
            "(epoch: 4, iters: 200, time: 0.079, data: 0.002) G_GAN: 2.764 G_L1: 36.451 D_real: 0.014 D_fake: 0.320 \n",
            "(epoch: 4, iters: 300, time: 0.093, data: 0.009) G_GAN: 1.959 G_L1: 27.413 D_real: 1.082 D_fake: 0.164 \n",
            "(epoch: 4, iters: 400, time: 0.167, data: 0.002) G_GAN: 2.000 G_L1: 31.664 D_real: 0.013 D_fake: 1.314 \n",
            "End of epoch 4 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.093, data: 0.125) G_GAN: 1.298 G_L1: 33.447 D_real: 0.250 D_fake: 0.134 \n",
            "(epoch: 5, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.686 G_L1: 41.236 D_real: 0.204 D_fake: 0.274 \n",
            "(epoch: 5, iters: 300, time: 0.092, data: 0.002) G_GAN: 1.924 G_L1: 33.432 D_real: 0.320 D_fake: 0.347 \n",
            "(epoch: 5, iters: 400, time: 0.173, data: 0.002) G_GAN: 1.597 G_L1: 34.676 D_real: 0.295 D_fake: 0.635 \n",
            "saving the model at the end of epoch 5, iters 2000\n",
            "End of epoch 5 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.090, data: 0.160) G_GAN: 1.683 G_L1: 43.814 D_real: 0.058 D_fake: 0.243 \n",
            "(epoch: 6, iters: 200, time: 0.084, data: 0.002) G_GAN: 1.858 G_L1: 28.770 D_real: 0.190 D_fake: 0.164 \n",
            "(epoch: 6, iters: 300, time: 0.090, data: 0.008) G_GAN: 3.100 G_L1: 55.195 D_real: 0.001 D_fake: 0.057 \n",
            "(epoch: 6, iters: 400, time: 0.183, data: 0.002) G_GAN: 2.627 G_L1: 33.803 D_real: 0.252 D_fake: 0.102 \n",
            "End of epoch 6 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.092, data: 0.241) G_GAN: 3.009 G_L1: 30.328 D_real: 0.072 D_fake: 0.407 \n",
            "(epoch: 7, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.733 G_L1: 46.791 D_real: 0.001 D_fake: 0.418 \n",
            "(epoch: 7, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.968 G_L1: 38.643 D_real: 0.207 D_fake: 0.040 \n",
            "(epoch: 7, iters: 400, time: 0.171, data: 0.002) G_GAN: 1.972 G_L1: 34.840 D_real: 0.009 D_fake: 0.677 \n",
            "End of epoch 7 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.093, data: 0.205) G_GAN: 2.757 G_L1: 43.028 D_real: 0.168 D_fake: 0.348 \n",
            "(epoch: 8, iters: 200, time: 0.091, data: 0.002) G_GAN: 4.212 G_L1: 44.963 D_real: 0.004 D_fake: 0.031 \n",
            "(epoch: 8, iters: 300, time: 0.093, data: 0.002) G_GAN: 1.995 G_L1: 48.005 D_real: 0.001 D_fake: 0.237 \n",
            "(epoch: 8, iters: 400, time: 0.180, data: 0.002) G_GAN: 2.247 G_L1: 31.582 D_real: 0.336 D_fake: 0.340 \n",
            "End of epoch 8 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.077, data: 0.144) G_GAN: 2.589 G_L1: 32.238 D_real: 0.006 D_fake: 0.669 \n",
            "(epoch: 9, iters: 200, time: 0.092, data: 0.002) G_GAN: 1.860 G_L1: 30.922 D_real: 2.310 D_fake: 0.048 \n",
            "(epoch: 9, iters: 300, time: 0.081, data: 0.002) G_GAN: 1.938 G_L1: 35.266 D_real: 0.009 D_fake: 0.448 \n",
            "(epoch: 9, iters: 400, time: 0.168, data: 0.008) G_GAN: 2.456 G_L1: 32.348 D_real: 0.008 D_fake: 0.504 \n",
            "End of epoch 9 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.092, data: 0.143) G_GAN: 1.576 G_L1: 34.065 D_real: 0.065 D_fake: 0.414 \n",
            "(epoch: 10, iters: 200, time: 0.092, data: 0.002) G_GAN: 0.667 G_L1: 23.610 D_real: 2.746 D_fake: 0.554 \n",
            "(epoch: 10, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.411 G_L1: 42.449 D_real: 0.037 D_fake: 0.029 \n",
            "(epoch: 10, iters: 400, time: 0.190, data: 0.002) G_GAN: 3.701 G_L1: 39.144 D_real: 0.005 D_fake: 0.042 \n",
            "saving the model at the end of epoch 10, iters 4000\n",
            "End of epoch 10 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.093, data: 0.190) G_GAN: 0.267 G_L1: 23.275 D_real: 4.295 D_fake: 0.096 \n",
            "(epoch: 11, iters: 200, time: 0.091, data: 0.002) G_GAN: 2.792 G_L1: 33.292 D_real: 0.030 D_fake: 0.388 \n",
            "(epoch: 11, iters: 300, time: 0.093, data: 0.002) G_GAN: 4.592 G_L1: 36.262 D_real: 0.101 D_fake: 0.017 \n",
            "(epoch: 11, iters: 400, time: 0.194, data: 0.002) G_GAN: 2.682 G_L1: 37.637 D_real: 0.158 D_fake: 0.113 \n",
            "End of epoch 11 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.091, data: 0.174) G_GAN: 2.177 G_L1: 45.024 D_real: 0.001 D_fake: 0.128 \n",
            "(epoch: 12, iters: 200, time: 0.079, data: 0.002) G_GAN: 2.531 G_L1: 28.684 D_real: 1.543 D_fake: 0.032 \n",
            "(epoch: 12, iters: 300, time: 0.063, data: 0.002) G_GAN: 2.153 G_L1: 40.383 D_real: 0.022 D_fake: 0.289 \n",
            "(epoch: 12, iters: 400, time: 0.204, data: 0.003) G_GAN: 2.711 G_L1: 30.966 D_real: 0.451 D_fake: 0.056 \n",
            "End of epoch 12 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.093, data: 0.274) G_GAN: 2.353 G_L1: 26.837 D_real: 0.069 D_fake: 0.117 \n",
            "(epoch: 13, iters: 200, time: 0.100, data: 0.002) G_GAN: 2.000 G_L1: 32.796 D_real: 0.012 D_fake: 0.499 \n",
            "saving the latest model (epoch 13, total_iters 5000)\n",
            "(epoch: 13, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.279 G_L1: 45.593 D_real: 0.036 D_fake: 0.119 \n",
            "(epoch: 13, iters: 400, time: 0.214, data: 0.002) G_GAN: 2.874 G_L1: 39.819 D_real: 0.163 D_fake: 0.088 \n",
            "End of epoch 13 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.092, data: 0.302) G_GAN: 2.576 G_L1: 30.770 D_real: 0.144 D_fake: 0.090 \n",
            "(epoch: 14, iters: 200, time: 0.078, data: 0.002) G_GAN: 3.921 G_L1: 59.475 D_real: 0.000 D_fake: 0.039 \n",
            "(epoch: 14, iters: 300, time: 0.092, data: 0.005) G_GAN: 4.157 G_L1: 25.800 D_real: 0.644 D_fake: 0.017 \n",
            "(epoch: 14, iters: 400, time: 0.190, data: 0.002) G_GAN: 2.583 G_L1: 45.686 D_real: 0.002 D_fake: 1.107 \n",
            "End of epoch 14 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.092, data: 0.164) G_GAN: 1.896 G_L1: 37.916 D_real: 0.008 D_fake: 0.225 \n",
            "(epoch: 15, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.306 G_L1: 39.229 D_real: 0.001 D_fake: 0.081 \n",
            "(epoch: 15, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.802 G_L1: 43.131 D_real: 0.001 D_fake: 0.213 \n",
            "(epoch: 15, iters: 400, time: 0.196, data: 0.002) G_GAN: 1.332 G_L1: 42.624 D_real: 0.009 D_fake: 0.523 \n",
            "saving the model at the end of epoch 15, iters 6000\n",
            "End of epoch 15 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.092, data: 0.189) G_GAN: 2.492 G_L1: 40.133 D_real: 0.004 D_fake: 0.171 \n",
            "(epoch: 16, iters: 200, time: 0.089, data: 0.002) G_GAN: 1.635 G_L1: 30.760 D_real: 0.381 D_fake: 0.520 \n",
            "(epoch: 16, iters: 300, time: 0.092, data: 0.002) G_GAN: 1.973 G_L1: 33.773 D_real: 0.043 D_fake: 1.672 \n",
            "(epoch: 16, iters: 400, time: 0.194, data: 0.002) G_GAN: 1.722 G_L1: 27.760 D_real: 0.688 D_fake: 0.044 \n",
            "End of epoch 16 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.082, data: 0.176) G_GAN: 2.049 G_L1: 26.980 D_real: 0.080 D_fake: 0.539 \n",
            "(epoch: 17, iters: 200, time: 0.094, data: 0.009) G_GAN: 2.639 G_L1: 31.283 D_real: 0.395 D_fake: 0.045 \n",
            "(epoch: 17, iters: 300, time: 0.076, data: 0.002) G_GAN: 2.660 G_L1: 34.862 D_real: 0.053 D_fake: 0.796 \n",
            "(epoch: 17, iters: 400, time: 0.194, data: 0.002) G_GAN: 2.462 G_L1: 35.244 D_real: 0.072 D_fake: 0.420 \n",
            "End of epoch 17 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.155, data: 0.155) G_GAN: 2.153 G_L1: 27.676 D_real: 0.042 D_fake: 1.116 \n",
            "(epoch: 18, iters: 200, time: 0.093, data: 0.014) G_GAN: 2.275 G_L1: 26.872 D_real: 0.564 D_fake: 0.061 \n",
            "(epoch: 18, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.413 G_L1: 43.014 D_real: 0.006 D_fake: 0.050 \n",
            "(epoch: 18, iters: 400, time: 0.196, data: 0.002) G_GAN: 1.160 G_L1: 36.174 D_real: 0.762 D_fake: 0.267 \n",
            "End of epoch 18 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.092, data: 0.204) G_GAN: 1.615 G_L1: 24.217 D_real: 0.709 D_fake: 1.176 \n",
            "(epoch: 19, iters: 200, time: 0.091, data: 0.002) G_GAN: 4.042 G_L1: 52.760 D_real: 0.005 D_fake: 0.026 \n",
            "(epoch: 19, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.256 G_L1: 36.124 D_real: 0.097 D_fake: 0.209 \n",
            "(epoch: 19, iters: 400, time: 0.207, data: 0.002) G_GAN: 1.264 G_L1: 23.651 D_real: 0.169 D_fake: 0.564 \n",
            "End of epoch 19 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.091, data: 0.183) G_GAN: 1.446 G_L1: 28.919 D_real: 1.045 D_fake: 0.373 \n",
            "(epoch: 20, iters: 200, time: 0.080, data: 0.002) G_GAN: 2.995 G_L1: 32.665 D_real: 0.013 D_fake: 0.097 \n",
            "(epoch: 20, iters: 300, time: 0.092, data: 0.003) G_GAN: 2.199 G_L1: 30.023 D_real: 1.331 D_fake: 0.018 \n",
            "(epoch: 20, iters: 400, time: 0.206, data: 0.002) G_GAN: 1.419 G_L1: 25.065 D_real: 0.259 D_fake: 0.507 \n",
            "saving the model at the end of epoch 20, iters 8000\n",
            "End of epoch 20 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.093, data: 0.196) G_GAN: 1.064 G_L1: 30.095 D_real: 0.783 D_fake: 0.402 \n",
            "(epoch: 21, iters: 200, time: 0.088, data: 0.002) G_GAN: 2.857 G_L1: 33.924 D_real: 0.078 D_fake: 0.305 \n",
            "(epoch: 21, iters: 300, time: 0.088, data: 0.008) G_GAN: 1.138 G_L1: 25.694 D_real: 1.830 D_fake: 0.027 \n",
            "(epoch: 21, iters: 400, time: 0.233, data: 0.002) G_GAN: 2.811 G_L1: 36.370 D_real: 0.091 D_fake: 0.120 \n",
            "End of epoch 21 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.093, data: 0.281) G_GAN: 1.611 G_L1: 24.647 D_real: 0.152 D_fake: 0.479 \n",
            "(epoch: 22, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.017 G_L1: 24.782 D_real: 0.029 D_fake: 0.137 \n",
            "(epoch: 22, iters: 300, time: 0.092, data: 0.002) G_GAN: 1.601 G_L1: 29.697 D_real: 0.095 D_fake: 0.400 \n",
            "(epoch: 22, iters: 400, time: 0.210, data: 0.002) G_GAN: 3.112 G_L1: 30.711 D_real: 0.408 D_fake: 0.039 \n",
            "End of epoch 22 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.094, data: 0.170) G_GAN: 2.321 G_L1: 31.066 D_real: 0.095 D_fake: 0.290 \n",
            "(epoch: 23, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.139 G_L1: 30.029 D_real: 0.129 D_fake: 0.851 \n",
            "(epoch: 23, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.318 G_L1: 36.736 D_real: 0.307 D_fake: 0.028 \n",
            "(epoch: 23, iters: 400, time: 0.203, data: 0.002) G_GAN: 3.811 G_L1: 38.337 D_real: 0.080 D_fake: 0.030 \n",
            "End of epoch 23 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.080, data: 0.155) G_GAN: 2.816 G_L1: 27.358 D_real: 0.080 D_fake: 0.291 \n",
            "(epoch: 24, iters: 200, time: 0.092, data: 0.010) G_GAN: 3.182 G_L1: 40.532 D_real: 0.031 D_fake: 0.180 \n",
            "(epoch: 24, iters: 300, time: 0.086, data: 0.002) G_GAN: 0.491 G_L1: 20.559 D_real: 2.214 D_fake: 0.276 \n",
            "(epoch: 24, iters: 400, time: 0.226, data: 0.002) G_GAN: 3.277 G_L1: 38.880 D_real: 0.011 D_fake: 1.232 \n",
            "End of epoch 24 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.091, data: 0.155) G_GAN: 2.346 G_L1: 24.739 D_real: 0.266 D_fake: 0.125 \n",
            "(epoch: 25, iters: 200, time: 0.094, data: 0.002) G_GAN: 2.480 G_L1: 33.192 D_real: 0.015 D_fake: 0.105 \n",
            "(epoch: 25, iters: 300, time: 0.093, data: 0.002) G_GAN: 1.551 G_L1: 29.056 D_real: 0.065 D_fake: 0.352 \n",
            "(epoch: 25, iters: 400, time: 0.214, data: 0.002) G_GAN: 2.095 G_L1: 33.293 D_real: 0.005 D_fake: 0.272 \n",
            "saving the latest model (epoch 25, total_iters 10000)\n",
            "saving the model at the end of epoch 25, iters 10000\n",
            "End of epoch 25 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.092, data: 0.208) G_GAN: 1.991 G_L1: 25.455 D_real: 0.547 D_fake: 0.710 \n",
            "(epoch: 26, iters: 200, time: 0.092, data: 0.002) G_GAN: 4.583 G_L1: 36.253 D_real: 0.075 D_fake: 0.034 \n",
            "(epoch: 26, iters: 300, time: 0.078, data: 0.002) G_GAN: 1.558 G_L1: 35.321 D_real: 0.092 D_fake: 0.867 \n",
            "(epoch: 26, iters: 400, time: 0.211, data: 0.002) G_GAN: 1.833 G_L1: 26.982 D_real: 0.787 D_fake: 0.065 \n",
            "End of epoch 26 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.080, data: 0.156) G_GAN: 2.157 G_L1: 28.340 D_real: 0.277 D_fake: 0.095 \n",
            "(epoch: 27, iters: 200, time: 0.090, data: 0.013) G_GAN: 3.287 G_L1: 31.004 D_real: 0.226 D_fake: 0.032 \n",
            "(epoch: 27, iters: 300, time: 0.094, data: 0.002) G_GAN: 2.288 G_L1: 33.555 D_real: 0.063 D_fake: 0.221 \n",
            "(epoch: 27, iters: 400, time: 0.212, data: 0.009) G_GAN: 1.475 G_L1: 23.865 D_real: 3.174 D_fake: 0.030 \n",
            "End of epoch 27 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.092, data: 0.184) G_GAN: 3.386 G_L1: 21.561 D_real: 0.355 D_fake: 0.032 \n",
            "(epoch: 28, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.317 G_L1: 42.112 D_real: 0.001 D_fake: 0.070 \n",
            "(epoch: 28, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.238 G_L1: 25.873 D_real: 0.030 D_fake: 0.308 \n",
            "(epoch: 28, iters: 400, time: 0.218, data: 0.002) G_GAN: 2.306 G_L1: 39.349 D_real: 0.006 D_fake: 0.504 \n",
            "End of epoch 28 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.090, data: 0.233) G_GAN: 2.571 G_L1: 24.205 D_real: 1.076 D_fake: 0.021 \n",
            "(epoch: 29, iters: 200, time: 0.084, data: 0.002) G_GAN: 2.406 G_L1: 42.688 D_real: 0.015 D_fake: 0.156 \n",
            "(epoch: 29, iters: 300, time: 0.092, data: 0.003) G_GAN: 1.026 G_L1: 30.050 D_real: 0.946 D_fake: 0.246 \n",
            "(epoch: 29, iters: 400, time: 0.243, data: 0.002) G_GAN: 1.218 G_L1: 21.104 D_real: 2.153 D_fake: 0.089 \n",
            "End of epoch 29 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.093, data: 0.294) G_GAN: 2.573 G_L1: 45.523 D_real: 0.000 D_fake: 0.345 \n",
            "(epoch: 30, iters: 200, time: 0.087, data: 0.002) G_GAN: 0.733 G_L1: 25.191 D_real: 1.664 D_fake: 0.206 \n",
            "(epoch: 30, iters: 300, time: 0.093, data: 0.007) G_GAN: 1.952 G_L1: 29.093 D_real: 0.103 D_fake: 0.427 \n",
            "(epoch: 30, iters: 400, time: 0.222, data: 0.002) G_GAN: 2.666 G_L1: 27.372 D_real: 0.070 D_fake: 0.282 \n",
            "saving the model at the end of epoch 30, iters 12000\n",
            "End of epoch 30 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.093, data: 0.282) G_GAN: 2.548 G_L1: 28.529 D_real: 0.098 D_fake: 0.215 \n",
            "(epoch: 31, iters: 200, time: 0.092, data: 0.002) G_GAN: 1.697 G_L1: 30.593 D_real: 0.767 D_fake: 0.089 \n",
            "(epoch: 31, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.498 G_L1: 25.664 D_real: 0.019 D_fake: 0.558 \n",
            "(epoch: 31, iters: 400, time: 0.223, data: 0.002) G_GAN: 1.458 G_L1: 25.181 D_real: 0.313 D_fake: 0.131 \n",
            "End of epoch 31 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.091, data: 0.153) G_GAN: 3.171 G_L1: 38.194 D_real: 0.003 D_fake: 0.093 \n",
            "(epoch: 32, iters: 200, time: 0.091, data: 0.002) G_GAN: 1.731 G_L1: 26.412 D_real: 0.592 D_fake: 0.215 \n",
            "(epoch: 32, iters: 300, time: 0.089, data: 0.002) G_GAN: 2.564 G_L1: 28.809 D_real: 0.274 D_fake: 0.144 \n",
            "(epoch: 32, iters: 400, time: 0.225, data: 0.002) G_GAN: 2.776 G_L1: 34.390 D_real: 0.014 D_fake: 0.107 \n",
            "End of epoch 32 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.082, data: 0.136) G_GAN: 2.499 G_L1: 33.960 D_real: 0.415 D_fake: 0.064 \n",
            "(epoch: 33, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.392 G_L1: 25.450 D_real: 0.071 D_fake: 0.321 \n",
            "(epoch: 33, iters: 300, time: 0.083, data: 0.002) G_GAN: 3.111 G_L1: 23.105 D_real: 0.092 D_fake: 1.153 \n",
            "(epoch: 33, iters: 400, time: 0.234, data: 0.011) G_GAN: 1.849 G_L1: 28.735 D_real: 0.272 D_fake: 0.427 \n",
            "End of epoch 33 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.086, data: 0.157) G_GAN: 3.250 G_L1: 34.692 D_real: 0.253 D_fake: 0.030 \n",
            "(epoch: 34, iters: 200, time: 0.092, data: 0.002) G_GAN: 1.770 G_L1: 24.505 D_real: 1.825 D_fake: 0.024 \n",
            "(epoch: 34, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.111 G_L1: 29.117 D_real: 0.313 D_fake: 0.169 \n",
            "(epoch: 34, iters: 400, time: 0.235, data: 0.002) G_GAN: 1.752 G_L1: 26.306 D_real: 0.017 D_fake: 0.994 \n",
            "End of epoch 34 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.093, data: 0.170) G_GAN: 2.680 G_L1: 42.704 D_real: 0.000 D_fake: 0.175 \n",
            "(epoch: 35, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.452 G_L1: 35.528 D_real: 0.006 D_fake: 0.059 \n",
            "(epoch: 35, iters: 300, time: 0.093, data: 0.002) G_GAN: 1.329 G_L1: 29.472 D_real: 0.688 D_fake: 0.326 \n",
            "(epoch: 35, iters: 400, time: 0.257, data: 0.002) G_GAN: 2.557 G_L1: 30.261 D_real: 0.592 D_fake: 0.051 \n",
            "saving the model at the end of epoch 35, iters 14000\n",
            "End of epoch 35 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.092, data: 0.199) G_GAN: 2.130 G_L1: 24.551 D_real: 0.068 D_fake: 0.500 \n",
            "(epoch: 36, iters: 200, time: 0.078, data: 0.002) G_GAN: 2.510 G_L1: 37.543 D_real: 0.008 D_fake: 0.353 \n",
            "(epoch: 36, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.252 G_L1: 25.268 D_real: 0.716 D_fake: 0.061 \n",
            "(epoch: 36, iters: 400, time: 0.262, data: 0.002) G_GAN: 2.458 G_L1: 28.051 D_real: 0.116 D_fake: 0.190 \n",
            "End of epoch 36 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.091, data: 0.305) G_GAN: 2.423 G_L1: 27.578 D_real: 0.247 D_fake: 0.307 \n",
            "(epoch: 37, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.007 G_L1: 26.474 D_real: 0.656 D_fake: 0.141 \n",
            "(epoch: 37, iters: 300, time: 0.094, data: 0.002) G_GAN: 2.461 G_L1: 28.126 D_real: 0.135 D_fake: 0.117 \n",
            "(epoch: 37, iters: 400, time: 0.235, data: 0.002) G_GAN: 3.040 G_L1: 29.719 D_real: 0.215 D_fake: 0.091 \n",
            "End of epoch 37 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.093, data: 0.167) G_GAN: 2.495 G_L1: 23.839 D_real: 0.712 D_fake: 0.033 \n",
            "(epoch: 38, iters: 200, time: 0.091, data: 0.002) G_GAN: 2.587 G_L1: 29.920 D_real: 0.019 D_fake: 0.669 \n",
            "saving the latest model (epoch 38, total_iters 15000)\n",
            "(epoch: 38, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.888 G_L1: 27.749 D_real: 0.120 D_fake: 0.029 \n",
            "(epoch: 38, iters: 400, time: 0.245, data: 0.002) G_GAN: 3.667 G_L1: 32.728 D_real: 0.094 D_fake: 0.042 \n",
            "End of epoch 38 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.092, data: 0.209) G_GAN: 3.568 G_L1: 29.544 D_real: 0.152 D_fake: 0.038 \n",
            "(epoch: 39, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.769 G_L1: 31.376 D_real: 0.105 D_fake: 0.132 \n",
            "(epoch: 39, iters: 300, time: 0.082, data: 0.002) G_GAN: 3.514 G_L1: 34.717 D_real: 0.500 D_fake: 0.018 \n",
            "(epoch: 39, iters: 400, time: 0.239, data: 0.002) G_GAN: 2.350 G_L1: 20.967 D_real: 0.156 D_fake: 0.148 \n",
            "End of epoch 39 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.080, data: 0.169) G_GAN: 1.137 G_L1: 22.611 D_real: 1.701 D_fake: 0.115 \n",
            "(epoch: 40, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.101 G_L1: 31.057 D_real: 0.212 D_fake: 0.639 \n",
            "(epoch: 40, iters: 300, time: 0.092, data: 0.002) G_GAN: 1.861 G_L1: 23.280 D_real: 0.079 D_fake: 0.972 \n",
            "(epoch: 40, iters: 400, time: 0.243, data: 0.002) G_GAN: 1.383 G_L1: 30.287 D_real: 0.181 D_fake: 0.523 \n",
            "saving the model at the end of epoch 40, iters 16000\n",
            "End of epoch 40 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.077, data: 0.226) G_GAN: 2.429 G_L1: 25.214 D_real: 0.421 D_fake: 0.078 \n",
            "(epoch: 41, iters: 200, time: 0.086, data: 0.008) G_GAN: 2.717 G_L1: 24.671 D_real: 0.367 D_fake: 0.086 \n",
            "(epoch: 41, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.059 G_L1: 28.203 D_real: 0.478 D_fake: 0.023 \n",
            "(epoch: 41, iters: 400, time: 0.252, data: 0.002) G_GAN: 2.369 G_L1: 33.046 D_real: 0.010 D_fake: 0.178 \n",
            "End of epoch 41 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.091, data: 0.144) G_GAN: 2.575 G_L1: 23.430 D_real: 0.006 D_fake: 1.172 \n",
            "(epoch: 42, iters: 200, time: 0.094, data: 0.002) G_GAN: 4.343 G_L1: 27.472 D_real: 0.048 D_fake: 1.151 \n",
            "(epoch: 42, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.011 G_L1: 26.829 D_real: 0.836 D_fake: 0.088 \n",
            "(epoch: 42, iters: 400, time: 0.291, data: 0.002) G_GAN: 3.176 G_L1: 33.562 D_real: 0.209 D_fake: 0.071 \n",
            "End of epoch 42 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.092, data: 0.203) G_GAN: 2.863 G_L1: 25.540 D_real: 0.092 D_fake: 0.275 \n",
            "(epoch: 43, iters: 200, time: 0.072, data: 0.002) G_GAN: 2.270 G_L1: 30.547 D_real: 0.018 D_fake: 0.946 \n",
            "(epoch: 43, iters: 300, time: 0.093, data: 0.008) G_GAN: 1.637 G_L1: 19.926 D_real: 1.521 D_fake: 0.083 \n",
            "(epoch: 43, iters: 400, time: 0.253, data: 0.002) G_GAN: 2.261 G_L1: 46.483 D_real: 0.000 D_fake: 0.836 \n",
            "End of epoch 43 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.093, data: 0.240) G_GAN: 1.835 G_L1: 25.307 D_real: 0.132 D_fake: 0.505 \n",
            "(epoch: 44, iters: 200, time: 0.094, data: 0.002) G_GAN: 2.407 G_L1: 22.471 D_real: 0.265 D_fake: 0.093 \n",
            "(epoch: 44, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.261 G_L1: 53.961 D_real: 0.001 D_fake: 0.257 \n",
            "(epoch: 44, iters: 400, time: 0.255, data: 0.002) G_GAN: 3.433 G_L1: 39.989 D_real: 0.001 D_fake: 0.085 \n",
            "End of epoch 44 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.090, data: 0.139) G_GAN: 0.880 G_L1: 19.779 D_real: 0.964 D_fake: 0.370 \n",
            "(epoch: 45, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.679 G_L1: 29.471 D_real: 0.023 D_fake: 0.337 \n",
            "(epoch: 45, iters: 300, time: 0.088, data: 0.002) G_GAN: 2.364 G_L1: 31.919 D_real: 0.019 D_fake: 0.555 \n",
            "(epoch: 45, iters: 400, time: 0.256, data: 0.002) G_GAN: 1.376 G_L1: 18.428 D_real: 0.374 D_fake: 0.249 \n",
            "saving the model at the end of epoch 45, iters 18000\n",
            "End of epoch 45 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.078, data: 0.190) G_GAN: 3.049 G_L1: 34.130 D_real: 0.009 D_fake: 0.128 \n",
            "(epoch: 46, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.279 G_L1: 25.725 D_real: 0.248 D_fake: 0.115 \n",
            "(epoch: 46, iters: 300, time: 0.077, data: 0.002) G_GAN: 3.149 G_L1: 33.634 D_real: 0.268 D_fake: 0.050 \n",
            "(epoch: 46, iters: 400, time: 0.246, data: 0.014) G_GAN: 2.244 G_L1: 16.935 D_real: 0.118 D_fake: 0.114 \n",
            "End of epoch 46 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.086, data: 0.173) G_GAN: 3.021 G_L1: 36.564 D_real: 0.003 D_fake: 0.314 \n",
            "(epoch: 47, iters: 200, time: 0.091, data: 0.014) G_GAN: 2.905 G_L1: 27.881 D_real: 0.309 D_fake: 0.065 \n",
            "(epoch: 47, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.483 G_L1: 30.778 D_real: 0.011 D_fake: 0.631 \n",
            "(epoch: 47, iters: 400, time: 0.257, data: 0.002) G_GAN: 2.491 G_L1: 23.281 D_real: 0.165 D_fake: 0.118 \n",
            "End of epoch 47 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 0.092, data: 0.164) G_GAN: 2.900 G_L1: 28.644 D_real: 0.431 D_fake: 0.050 \n",
            "(epoch: 48, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.223 G_L1: 23.952 D_real: 0.104 D_fake: 0.569 \n",
            "(epoch: 48, iters: 300, time: 0.091, data: 0.002) G_GAN: 2.586 G_L1: 25.274 D_real: 0.134 D_fake: 0.413 \n",
            "(epoch: 48, iters: 400, time: 0.300, data: 0.002) G_GAN: 2.863 G_L1: 34.845 D_real: 0.077 D_fake: 1.217 \n",
            "End of epoch 48 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.092, data: 0.138) G_GAN: 2.064 G_L1: 27.377 D_real: 0.208 D_fake: 0.201 \n",
            "(epoch: 49, iters: 200, time: 0.091, data: 0.002) G_GAN: 1.877 G_L1: 32.999 D_real: 0.224 D_fake: 0.227 \n",
            "(epoch: 49, iters: 300, time: 0.092, data: 0.013) G_GAN: 3.085 G_L1: 23.677 D_real: 0.079 D_fake: 0.131 \n",
            "(epoch: 49, iters: 400, time: 0.266, data: 0.002) G_GAN: 1.507 G_L1: 24.193 D_real: 0.612 D_fake: 0.182 \n",
            "End of epoch 49 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.091, data: 0.250) G_GAN: 1.033 G_L1: 25.745 D_real: 0.955 D_fake: 0.328 \n",
            "(epoch: 50, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.148 G_L1: 24.527 D_real: 0.662 D_fake: 0.175 \n",
            "(epoch: 50, iters: 300, time: 0.091, data: 0.002) G_GAN: 1.494 G_L1: 22.486 D_real: 1.242 D_fake: 0.096 \n",
            "(epoch: 50, iters: 400, time: 0.269, data: 0.002) G_GAN: 2.497 G_L1: 27.229 D_real: 0.130 D_fake: 0.821 \n",
            "saving the latest model (epoch 50, total_iters 20000)\n",
            "saving the model at the end of epoch 50, iters 20000\n",
            "End of epoch 50 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.092, data: 0.245) G_GAN: 2.711 G_L1: 21.450 D_real: 0.095 D_fake: 0.206 \n",
            "(epoch: 51, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.140 G_L1: 31.912 D_real: 0.428 D_fake: 0.040 \n",
            "(epoch: 51, iters: 300, time: 0.095, data: 0.002) G_GAN: 3.525 G_L1: 25.800 D_real: 0.014 D_fake: 1.194 \n",
            "(epoch: 51, iters: 400, time: 0.253, data: 0.002) G_GAN: 3.198 G_L1: 30.070 D_real: 0.013 D_fake: 0.245 \n",
            "End of epoch 51 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 0.092, data: 0.163) G_GAN: 1.375 G_L1: 23.034 D_real: 0.851 D_fake: 0.757 \n",
            "(epoch: 52, iters: 200, time: 0.081, data: 0.002) G_GAN: 3.268 G_L1: 30.747 D_real: 0.165 D_fake: 0.045 \n",
            "(epoch: 52, iters: 300, time: 0.078, data: 0.013) G_GAN: 2.475 G_L1: 29.868 D_real: 0.011 D_fake: 0.542 \n",
            "(epoch: 52, iters: 400, time: 0.310, data: 0.002) G_GAN: 3.376 G_L1: 34.314 D_real: 0.017 D_fake: 0.950 \n",
            "End of epoch 52 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.094, data: 0.265) G_GAN: 2.248 G_L1: 22.115 D_real: 1.276 D_fake: 0.025 \n",
            "(epoch: 53, iters: 200, time: 0.079, data: 0.002) G_GAN: 2.697 G_L1: 31.372 D_real: 0.011 D_fake: 0.813 \n",
            "(epoch: 53, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.124 G_L1: 28.771 D_real: 0.010 D_fake: 0.122 \n",
            "(epoch: 53, iters: 400, time: 0.519, data: 0.002) G_GAN: 1.633 G_L1: 18.320 D_real: 2.855 D_fake: 0.048 \n",
            "End of epoch 53 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.091, data: 0.188) G_GAN: 3.132 G_L1: 28.443 D_real: 0.675 D_fake: 0.035 \n",
            "(epoch: 54, iters: 200, time: 0.089, data: 0.002) G_GAN: 2.544 G_L1: 30.096 D_real: 0.003 D_fake: 0.473 \n",
            "(epoch: 54, iters: 300, time: 0.084, data: 0.002) G_GAN: 2.409 G_L1: 29.188 D_real: 0.007 D_fake: 0.224 \n",
            "(epoch: 54, iters: 400, time: 0.285, data: 0.002) G_GAN: 3.488 G_L1: 24.772 D_real: 0.066 D_fake: 0.058 \n",
            "End of epoch 54 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.069, data: 0.196) G_GAN: 2.601 G_L1: 22.540 D_real: 0.074 D_fake: 0.236 \n",
            "(epoch: 55, iters: 200, time: 0.091, data: 0.002) G_GAN: 1.831 G_L1: 28.959 D_real: 0.629 D_fake: 0.063 \n",
            "(epoch: 55, iters: 300, time: 0.078, data: 0.002) G_GAN: 3.246 G_L1: 32.786 D_real: 0.025 D_fake: 0.202 \n",
            "(epoch: 55, iters: 400, time: 0.281, data: 0.002) G_GAN: 1.995 G_L1: 23.392 D_real: 0.003 D_fake: 0.778 \n",
            "saving the model at the end of epoch 55, iters 22000\n",
            "End of epoch 55 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 100, time: 0.082, data: 0.178) G_GAN: 2.309 G_L1: 28.174 D_real: 0.164 D_fake: 0.377 \n",
            "(epoch: 56, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.519 G_L1: 31.179 D_real: 0.000 D_fake: 0.398 \n",
            "(epoch: 56, iters: 300, time: 0.091, data: 0.002) G_GAN: 2.621 G_L1: 26.506 D_real: 0.204 D_fake: 0.364 \n",
            "(epoch: 56, iters: 400, time: 0.274, data: 0.002) G_GAN: 2.575 G_L1: 23.693 D_real: 0.535 D_fake: 0.086 \n",
            "End of epoch 56 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.092, data: 0.191) G_GAN: 2.786 G_L1: 32.452 D_real: 0.000 D_fake: 0.309 \n",
            "(epoch: 57, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.625 G_L1: 27.683 D_real: 0.212 D_fake: 0.155 \n",
            "(epoch: 57, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.738 G_L1: 17.744 D_real: 0.035 D_fake: 2.382 \n",
            "(epoch: 57, iters: 400, time: 0.272, data: 0.002) G_GAN: 2.220 G_L1: 23.044 D_real: 0.305 D_fake: 0.455 \n",
            "End of epoch 57 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.091, data: 0.180) G_GAN: 2.934 G_L1: 20.628 D_real: 0.033 D_fake: 0.543 \n",
            "(epoch: 58, iters: 200, time: 0.086, data: 0.002) G_GAN: 4.027 G_L1: 22.162 D_real: 0.041 D_fake: 1.375 \n",
            "(epoch: 58, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.439 G_L1: 43.982 D_real: 0.005 D_fake: 0.156 \n",
            "(epoch: 58, iters: 400, time: 0.314, data: 0.002) G_GAN: 2.706 G_L1: 27.532 D_real: 0.034 D_fake: 0.286 \n",
            "End of epoch 58 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.093, data: 0.319) G_GAN: 3.666 G_L1: 22.649 D_real: 0.009 D_fake: 0.748 \n",
            "(epoch: 59, iters: 200, time: 0.085, data: 0.002) G_GAN: 2.488 G_L1: 24.067 D_real: 0.309 D_fake: 0.121 \n",
            "(epoch: 59, iters: 300, time: 0.092, data: 0.013) G_GAN: 1.511 G_L1: 20.204 D_real: 0.600 D_fake: 0.110 \n",
            "(epoch: 59, iters: 400, time: 0.285, data: 0.002) G_GAN: 2.416 G_L1: 34.696 D_real: 0.089 D_fake: 0.204 \n",
            "End of epoch 59 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.092, data: 0.174) G_GAN: 5.138 G_L1: 30.338 D_real: 0.335 D_fake: 0.004 \n",
            "(epoch: 60, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.905 G_L1: 49.885 D_real: 0.065 D_fake: 0.461 \n",
            "(epoch: 60, iters: 300, time: 0.093, data: 0.002) G_GAN: 1.959 G_L1: 31.478 D_real: 0.162 D_fake: 0.330 \n",
            "(epoch: 60, iters: 400, time: 0.292, data: 0.002) G_GAN: 3.240 G_L1: 28.272 D_real: 0.155 D_fake: 0.060 \n",
            "saving the model at the end of epoch 60, iters 24000\n",
            "End of epoch 60 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.093, data: 0.196) G_GAN: 2.295 G_L1: 21.690 D_real: 0.164 D_fake: 0.180 \n",
            "(epoch: 61, iters: 200, time: 0.094, data: 0.002) G_GAN: 1.878 G_L1: 22.815 D_real: 0.363 D_fake: 0.161 \n",
            "(epoch: 61, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.935 G_L1: 26.062 D_real: 0.461 D_fake: 0.853 \n",
            "(epoch: 61, iters: 400, time: 0.292, data: 0.002) G_GAN: 2.980 G_L1: 30.936 D_real: 0.001 D_fake: 0.348 \n",
            "End of epoch 61 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.080, data: 0.153) G_GAN: 3.088 G_L1: 24.825 D_real: 0.111 D_fake: 0.074 \n",
            "(epoch: 62, iters: 200, time: 0.093, data: 0.013) G_GAN: 2.817 G_L1: 31.582 D_real: 0.104 D_fake: 0.089 \n",
            "(epoch: 62, iters: 300, time: 0.084, data: 0.002) G_GAN: 2.727 G_L1: 25.389 D_real: 0.192 D_fake: 0.112 \n",
            "(epoch: 62, iters: 400, time: 0.297, data: 0.011) G_GAN: 1.560 G_L1: 31.520 D_real: 1.290 D_fake: 0.040 \n",
            "End of epoch 62 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.093, data: 0.199) G_GAN: 3.639 G_L1: 24.336 D_real: 0.021 D_fake: 1.219 \n",
            "(epoch: 63, iters: 200, time: 0.091, data: 0.002) G_GAN: 2.196 G_L1: 26.350 D_real: 0.495 D_fake: 0.101 \n",
            "saving the latest model (epoch 63, total_iters 25000)\n",
            "(epoch: 63, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.685 G_L1: 22.115 D_real: 0.039 D_fake: 0.943 \n",
            "(epoch: 63, iters: 400, time: 0.312, data: 0.002) G_GAN: 2.505 G_L1: 29.812 D_real: 0.007 D_fake: 0.353 \n",
            "End of epoch 63 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 100, time: 0.091, data: 0.197) G_GAN: 4.123 G_L1: 28.735 D_real: 0.008 D_fake: 0.458 \n",
            "(epoch: 64, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.088 G_L1: 25.513 D_real: 0.077 D_fake: 0.164 \n",
            "(epoch: 64, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.059 G_L1: 25.613 D_real: 0.286 D_fake: 0.131 \n",
            "(epoch: 64, iters: 400, time: 0.289, data: 0.002) G_GAN: 2.892 G_L1: 37.480 D_real: 0.063 D_fake: 0.143 \n",
            "End of epoch 64 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.091, data: 0.172) G_GAN: 2.634 G_L1: 32.644 D_real: 0.030 D_fake: 0.193 \n",
            "(epoch: 65, iters: 200, time: 0.082, data: 0.002) G_GAN: 3.320 G_L1: 27.704 D_real: 0.075 D_fake: 0.152 \n",
            "(epoch: 65, iters: 300, time: 0.092, data: 0.003) G_GAN: 2.894 G_L1: 36.786 D_real: 0.131 D_fake: 0.197 \n",
            "(epoch: 65, iters: 400, time: 0.364, data: 0.002) G_GAN: 2.527 G_L1: 25.733 D_real: 0.620 D_fake: 0.083 \n",
            "saving the model at the end of epoch 65, iters 26000\n",
            "End of epoch 65 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.093, data: 0.156) G_GAN: 2.304 G_L1: 28.987 D_real: 0.024 D_fake: 0.189 \n",
            "(epoch: 66, iters: 200, time: 0.091, data: 0.002) G_GAN: 3.307 G_L1: 32.787 D_real: 0.003 D_fake: 1.456 \n",
            "(epoch: 66, iters: 300, time: 0.092, data: 0.002) G_GAN: 1.276 G_L1: 20.600 D_real: 2.194 D_fake: 0.046 \n",
            "(epoch: 66, iters: 400, time: 0.296, data: 0.002) G_GAN: 3.119 G_L1: 26.730 D_real: 0.166 D_fake: 0.087 \n",
            "End of epoch 66 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.093, data: 0.186) G_GAN: 2.890 G_L1: 32.623 D_real: 0.003 D_fake: 0.090 \n",
            "(epoch: 67, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.764 G_L1: 37.938 D_real: 0.042 D_fake: 0.230 \n",
            "(epoch: 67, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.312 G_L1: 21.859 D_real: 0.832 D_fake: 0.013 \n",
            "(epoch: 67, iters: 400, time: 0.365, data: 0.002) G_GAN: 3.592 G_L1: 28.772 D_real: 0.010 D_fake: 0.250 \n",
            "End of epoch 67 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 100, time: 0.093, data: 0.226) G_GAN: 1.201 G_L1: 21.487 D_real: 1.735 D_fake: 0.078 \n",
            "(epoch: 68, iters: 200, time: 0.074, data: 0.002) G_GAN: 1.587 G_L1: 27.474 D_real: 0.638 D_fake: 0.131 \n",
            "(epoch: 68, iters: 300, time: 0.092, data: 0.009) G_GAN: 2.716 G_L1: 28.570 D_real: 0.331 D_fake: 0.176 \n",
            "(epoch: 68, iters: 400, time: 0.299, data: 0.002) G_GAN: 2.985 G_L1: 32.536 D_real: 0.083 D_fake: 0.284 \n",
            "End of epoch 68 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.092, data: 0.206) G_GAN: 3.246 G_L1: 27.086 D_real: 0.028 D_fake: 0.116 \n",
            "(epoch: 69, iters: 200, time: 0.093, data: 0.002) G_GAN: 1.919 G_L1: 19.264 D_real: 0.345 D_fake: 0.147 \n",
            "(epoch: 69, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.081 G_L1: 22.844 D_real: 0.136 D_fake: 0.400 \n",
            "(epoch: 69, iters: 400, time: 0.300, data: 0.002) G_GAN: 2.329 G_L1: 32.530 D_real: 0.258 D_fake: 0.185 \n",
            "End of epoch 69 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.091, data: 0.196) G_GAN: 2.878 G_L1: 29.699 D_real: 0.359 D_fake: 0.067 \n",
            "(epoch: 70, iters: 200, time: 0.091, data: 0.002) G_GAN: 2.958 G_L1: 25.886 D_real: 0.175 D_fake: 0.060 \n",
            "(epoch: 70, iters: 300, time: 0.080, data: 0.002) G_GAN: 4.184 G_L1: 30.973 D_real: 0.018 D_fake: 1.320 \n",
            "(epoch: 70, iters: 400, time: 0.315, data: 0.003) G_GAN: 2.866 G_L1: 16.904 D_real: 0.127 D_fake: 0.125 \n",
            "saving the model at the end of epoch 70, iters 28000\n",
            "End of epoch 70 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.085, data: 0.205) G_GAN: 4.779 G_L1: 26.494 D_real: 0.120 D_fake: 0.012 \n",
            "(epoch: 71, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.226 G_L1: 24.473 D_real: 0.033 D_fake: 0.816 \n",
            "(epoch: 71, iters: 300, time: 0.077, data: 0.002) G_GAN: 2.815 G_L1: 19.811 D_real: 0.021 D_fake: 0.845 \n",
            "(epoch: 71, iters: 400, time: 0.314, data: 0.008) G_GAN: 3.333 G_L1: 26.794 D_real: 0.138 D_fake: 0.051 \n",
            "End of epoch 71 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 100, time: 0.081, data: 0.147) G_GAN: 2.643 G_L1: 30.673 D_real: 0.001 D_fake: 0.507 \n",
            "(epoch: 72, iters: 200, time: 0.094, data: 0.003) G_GAN: 4.265 G_L1: 30.623 D_real: 0.007 D_fake: 1.151 \n",
            "(epoch: 72, iters: 300, time: 0.090, data: 0.002) G_GAN: 2.688 G_L1: 27.463 D_real: 0.202 D_fake: 0.113 \n",
            "(epoch: 72, iters: 400, time: 0.314, data: 0.002) G_GAN: 3.519 G_L1: 30.331 D_real: 0.550 D_fake: 0.030 \n",
            "End of epoch 72 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.093, data: 0.202) G_GAN: 1.692 G_L1: 24.617 D_real: 0.413 D_fake: 0.410 \n",
            "(epoch: 73, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.577 G_L1: 20.765 D_real: 0.078 D_fake: 0.082 \n",
            "(epoch: 73, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.525 G_L1: 22.655 D_real: 0.159 D_fake: 0.052 \n",
            "(epoch: 73, iters: 400, time: 0.377, data: 0.002) G_GAN: 3.023 G_L1: 29.692 D_real: 0.369 D_fake: 0.031 \n",
            "End of epoch 73 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.092, data: 0.201) G_GAN: 2.600 G_L1: 24.086 D_real: 0.531 D_fake: 0.167 \n",
            "(epoch: 74, iters: 200, time: 0.082, data: 0.002) G_GAN: 1.123 G_L1: 19.645 D_real: 0.749 D_fake: 0.094 \n",
            "(epoch: 74, iters: 300, time: 0.093, data: 0.014) G_GAN: 2.504 G_L1: 23.267 D_real: 0.081 D_fake: 0.177 \n",
            "(epoch: 74, iters: 400, time: 0.678, data: 0.002) G_GAN: 1.477 G_L1: 21.270 D_real: 0.628 D_fake: 0.058 \n",
            "End of epoch 74 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.092, data: 0.303) G_GAN: 4.044 G_L1: 31.791 D_real: 0.016 D_fake: 0.054 \n",
            "(epoch: 75, iters: 200, time: 0.091, data: 0.002) G_GAN: 2.536 G_L1: 25.085 D_real: 0.032 D_fake: 0.184 \n",
            "(epoch: 75, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.581 G_L1: 25.139 D_real: 0.034 D_fake: 0.065 \n",
            "(epoch: 75, iters: 400, time: 0.325, data: 0.002) G_GAN: 2.992 G_L1: 27.393 D_real: 0.003 D_fake: 0.252 \n",
            "saving the latest model (epoch 75, total_iters 30000)\n",
            "saving the model at the end of epoch 75, iters 30000\n",
            "End of epoch 75 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 100, time: 0.091, data: 0.212) G_GAN: 2.847 G_L1: 24.677 D_real: 0.017 D_fake: 0.193 \n",
            "(epoch: 76, iters: 200, time: 0.094, data: 0.002) G_GAN: 3.170 G_L1: 25.910 D_real: 1.071 D_fake: 0.013 \n",
            "(epoch: 76, iters: 300, time: 0.084, data: 0.002) G_GAN: 2.290 G_L1: 22.881 D_real: 0.592 D_fake: 0.274 \n",
            "(epoch: 76, iters: 400, time: 0.322, data: 0.002) G_GAN: 3.220 G_L1: 24.904 D_real: 0.051 D_fake: 0.171 \n",
            "End of epoch 76 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.093, data: 0.189) G_GAN: 2.995 G_L1: 32.652 D_real: 0.009 D_fake: 0.166 \n",
            "(epoch: 77, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.624 G_L1: 24.171 D_real: 1.497 D_fake: 0.003 \n",
            "(epoch: 77, iters: 300, time: 0.092, data: 0.002) G_GAN: 5.274 G_L1: 30.874 D_real: 0.014 D_fake: 0.014 \n",
            "(epoch: 77, iters: 400, time: 0.385, data: 0.002) G_GAN: 2.998 G_L1: 23.126 D_real: 0.019 D_fake: 0.362 \n",
            "End of epoch 77 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.092, data: 0.316) G_GAN: 2.201 G_L1: 18.201 D_real: 0.501 D_fake: 0.071 \n",
            "(epoch: 78, iters: 200, time: 0.090, data: 0.002) G_GAN: 2.435 G_L1: 34.035 D_real: 0.030 D_fake: 0.292 \n",
            "(epoch: 78, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.693 G_L1: 22.190 D_real: 0.013 D_fake: 1.035 \n",
            "(epoch: 78, iters: 400, time: 0.343, data: 0.002) G_GAN: 2.663 G_L1: 29.927 D_real: 0.013 D_fake: 0.242 \n",
            "End of epoch 78 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.092, data: 0.148) G_GAN: 2.187 G_L1: 20.904 D_real: 0.212 D_fake: 0.360 \n",
            "(epoch: 79, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.937 G_L1: 35.397 D_real: 0.001 D_fake: 0.897 \n",
            "(epoch: 79, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.993 G_L1: 39.284 D_real: 0.030 D_fake: 0.144 \n",
            "(epoch: 79, iters: 400, time: 0.329, data: 0.002) G_GAN: 2.713 G_L1: 29.041 D_real: 0.069 D_fake: 0.341 \n",
            "End of epoch 79 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 100, time: 0.080, data: 0.202) G_GAN: 3.212 G_L1: 27.717 D_real: 0.038 D_fake: 0.200 \n",
            "(epoch: 80, iters: 200, time: 0.090, data: 0.002) G_GAN: 2.589 G_L1: 19.297 D_real: 0.400 D_fake: 0.052 \n",
            "(epoch: 80, iters: 300, time: 0.079, data: 0.002) G_GAN: 3.614 G_L1: 18.830 D_real: 0.130 D_fake: 0.176 \n",
            "(epoch: 80, iters: 400, time: 0.343, data: 0.002) G_GAN: 2.993 G_L1: 19.754 D_real: 0.011 D_fake: 0.140 \n",
            "saving the model at the end of epoch 80, iters 32000\n",
            "End of epoch 80 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.080, data: 0.235) G_GAN: 3.461 G_L1: 27.414 D_real: 0.017 D_fake: 0.196 \n",
            "(epoch: 81, iters: 200, time: 0.092, data: 0.011) G_GAN: 1.670 G_L1: 22.498 D_real: 0.442 D_fake: 0.187 \n",
            "(epoch: 81, iters: 300, time: 0.088, data: 0.002) G_GAN: 1.369 G_L1: 25.250 D_real: 0.532 D_fake: 0.026 \n",
            "(epoch: 81, iters: 400, time: 0.330, data: 0.011) G_GAN: 2.034 G_L1: 21.468 D_real: 0.477 D_fake: 0.057 \n",
            "End of epoch 81 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.093, data: 0.195) G_GAN: 3.846 G_L1: 27.787 D_real: 0.143 D_fake: 0.074 \n",
            "(epoch: 82, iters: 200, time: 0.091, data: 0.002) G_GAN: 4.877 G_L1: 25.286 D_real: 0.002 D_fake: 2.138 \n",
            "(epoch: 82, iters: 300, time: 0.091, data: 0.002) G_GAN: 4.197 G_L1: 28.405 D_real: 0.091 D_fake: 0.032 \n",
            "(epoch: 82, iters: 400, time: 0.344, data: 0.002) G_GAN: 1.449 G_L1: 24.786 D_real: 0.737 D_fake: 0.128 \n",
            "End of epoch 82 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.092, data: 0.182) G_GAN: 3.811 G_L1: 19.544 D_real: 1.860 D_fake: 0.003 \n",
            "(epoch: 83, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.903 G_L1: 21.111 D_real: 0.423 D_fake: 0.024 \n",
            "(epoch: 83, iters: 300, time: 0.091, data: 0.002) G_GAN: 2.402 G_L1: 22.019 D_real: 0.161 D_fake: 0.520 \n",
            "(epoch: 83, iters: 400, time: 0.422, data: 0.002) G_GAN: 3.831 G_L1: 28.006 D_real: 0.013 D_fake: 0.053 \n",
            "End of epoch 83 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 100, time: 0.092, data: 0.292) G_GAN: 3.989 G_L1: 24.369 D_real: 0.004 D_fake: 0.797 \n",
            "(epoch: 84, iters: 200, time: 0.080, data: 0.002) G_GAN: 3.438 G_L1: 32.913 D_real: 0.006 D_fake: 0.748 \n",
            "(epoch: 84, iters: 300, time: 0.090, data: 0.012) G_GAN: 3.325 G_L1: 29.650 D_real: 0.003 D_fake: 0.138 \n",
            "(epoch: 84, iters: 400, time: 0.336, data: 0.002) G_GAN: 3.022 G_L1: 22.532 D_real: 0.043 D_fake: 0.051 \n",
            "End of epoch 84 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.092, data: 0.166) G_GAN: 2.629 G_L1: 25.007 D_real: 0.224 D_fake: 0.234 \n",
            "(epoch: 85, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.228 G_L1: 33.107 D_real: 0.089 D_fake: 0.173 \n",
            "(epoch: 85, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.392 G_L1: 31.000 D_real: 0.033 D_fake: 0.155 \n",
            "(epoch: 85, iters: 400, time: 0.343, data: 0.002) G_GAN: 3.422 G_L1: 24.070 D_real: 0.482 D_fake: 0.012 \n",
            "saving the model at the end of epoch 85, iters 34000\n",
            "End of epoch 85 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.091, data: 0.176) G_GAN: 2.499 G_L1: 20.583 D_real: 0.124 D_fake: 0.119 \n",
            "(epoch: 86, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.109 G_L1: 28.906 D_real: 0.350 D_fake: 0.100 \n",
            "(epoch: 86, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.167 G_L1: 21.201 D_real: 0.013 D_fake: 0.134 \n",
            "(epoch: 86, iters: 400, time: 0.349, data: 0.002) G_GAN: 2.259 G_L1: 33.365 D_real: 0.005 D_fake: 0.392 \n",
            "End of epoch 86 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.076, data: 0.195) G_GAN: 4.699 G_L1: 27.361 D_real: 0.430 D_fake: 0.008 \n",
            "(epoch: 87, iters: 200, time: 0.092, data: 0.002) G_GAN: 4.071 G_L1: 25.637 D_real: 0.023 D_fake: 1.007 \n",
            "(epoch: 87, iters: 300, time: 0.088, data: 0.002) G_GAN: 2.356 G_L1: 25.927 D_real: 0.002 D_fake: 0.269 \n",
            "(epoch: 87, iters: 400, time: 0.619, data: 0.013) G_GAN: 4.147 G_L1: 29.130 D_real: 0.035 D_fake: 0.130 \n",
            "End of epoch 87 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 100, time: 0.076, data: 0.174) G_GAN: 2.384 G_L1: 28.497 D_real: 0.313 D_fake: 0.150 \n",
            "(epoch: 88, iters: 200, time: 0.093, data: 0.008) G_GAN: 3.160 G_L1: 26.087 D_real: 0.184 D_fake: 0.523 \n",
            "saving the latest model (epoch 88, total_iters 35000)\n",
            "(epoch: 88, iters: 300, time: 0.092, data: 0.003) G_GAN: 3.658 G_L1: 24.876 D_real: 0.019 D_fake: 0.033 \n",
            "(epoch: 88, iters: 400, time: 0.352, data: 0.002) G_GAN: 2.880 G_L1: 22.256 D_real: 0.836 D_fake: 0.021 \n",
            "End of epoch 88 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.092, data: 0.187) G_GAN: 2.465 G_L1: 19.969 D_real: 0.543 D_fake: 0.058 \n",
            "(epoch: 89, iters: 200, time: 0.090, data: 0.002) G_GAN: 3.048 G_L1: 20.747 D_real: 0.041 D_fake: 0.166 \n",
            "(epoch: 89, iters: 300, time: 0.094, data: 0.002) G_GAN: 2.220 G_L1: 27.207 D_real: 0.329 D_fake: 0.174 \n",
            "(epoch: 89, iters: 400, time: 0.350, data: 0.003) G_GAN: 3.181 G_L1: 27.956 D_real: 0.069 D_fake: 0.867 \n",
            "End of epoch 89 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.090, data: 0.182) G_GAN: 2.036 G_L1: 18.432 D_real: 0.334 D_fake: 0.180 \n",
            "(epoch: 90, iters: 200, time: 0.083, data: 0.002) G_GAN: 2.247 G_L1: 27.835 D_real: 0.081 D_fake: 0.261 \n",
            "(epoch: 90, iters: 300, time: 0.076, data: 0.002) G_GAN: 3.821 G_L1: 30.229 D_real: 0.001 D_fake: 1.367 \n",
            "(epoch: 90, iters: 400, time: 0.420, data: 0.009) G_GAN: 1.641 G_L1: 21.023 D_real: 0.622 D_fake: 0.106 \n",
            "saving the model at the end of epoch 90, iters 36000\n",
            "End of epoch 90 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.091, data: 0.213) G_GAN: 3.818 G_L1: 19.078 D_real: 0.060 D_fake: 0.165 \n",
            "(epoch: 91, iters: 200, time: 0.071, data: 0.002) G_GAN: 3.340 G_L1: 27.502 D_real: 0.436 D_fake: 0.046 \n",
            "(epoch: 91, iters: 300, time: 0.089, data: 0.002) G_GAN: 4.486 G_L1: 29.625 D_real: 0.003 D_fake: 0.978 \n",
            "(epoch: 91, iters: 400, time: 0.409, data: 0.002) G_GAN: 2.236 G_L1: 27.333 D_real: 0.008 D_fake: 0.378 \n",
            "End of epoch 91 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 100, time: 0.093, data: 0.292) G_GAN: 3.769 G_L1: 38.290 D_real: 0.009 D_fake: 0.060 \n",
            "(epoch: 92, iters: 200, time: 0.092, data: 0.002) G_GAN: 4.233 G_L1: 21.585 D_real: 0.028 D_fake: 0.032 \n",
            "(epoch: 92, iters: 300, time: 0.094, data: 0.002) G_GAN: 3.365 G_L1: 16.651 D_real: 0.053 D_fake: 0.497 \n",
            "(epoch: 92, iters: 400, time: 0.361, data: 0.002) G_GAN: 1.995 G_L1: 17.326 D_real: 0.459 D_fake: 0.072 \n",
            "End of epoch 92 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.092, data: 0.169) G_GAN: 3.289 G_L1: 19.589 D_real: 0.128 D_fake: 0.065 \n",
            "(epoch: 93, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.180 G_L1: 17.577 D_real: 0.091 D_fake: 0.382 \n",
            "(epoch: 93, iters: 300, time: 0.093, data: 0.002) G_GAN: 4.028 G_L1: 27.687 D_real: 0.012 D_fake: 0.067 \n",
            "(epoch: 93, iters: 400, time: 0.353, data: 0.002) G_GAN: 6.661 G_L1: 26.952 D_real: 0.046 D_fake: 0.003 \n",
            "End of epoch 93 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.072, data: 0.143) G_GAN: 4.156 G_L1: 25.059 D_real: 0.899 D_fake: 0.010 \n",
            "(epoch: 94, iters: 200, time: 0.090, data: 0.008) G_GAN: 2.599 G_L1: 21.516 D_real: 0.172 D_fake: 0.242 \n",
            "(epoch: 94, iters: 300, time: 0.088, data: 0.002) G_GAN: 3.224 G_L1: 25.443 D_real: 0.012 D_fake: 0.159 \n",
            "(epoch: 94, iters: 400, time: 0.347, data: 0.011) G_GAN: 2.631 G_L1: 22.728 D_real: 0.028 D_fake: 0.393 \n",
            "End of epoch 94 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.092, data: 0.176) G_GAN: 3.396 G_L1: 20.916 D_real: 0.081 D_fake: 0.064 \n",
            "(epoch: 95, iters: 200, time: 0.092, data: 0.003) G_GAN: 4.853 G_L1: 25.724 D_real: 0.030 D_fake: 0.006 \n",
            "(epoch: 95, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.735 G_L1: 26.972 D_real: 0.000 D_fake: 0.190 \n",
            "(epoch: 95, iters: 400, time: 0.366, data: 0.002) G_GAN: 3.598 G_L1: 26.930 D_real: 0.090 D_fake: 0.055 \n",
            "saving the model at the end of epoch 95, iters 38000\n",
            "End of epoch 95 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 100, time: 0.092, data: 0.181) G_GAN: 2.914 G_L1: 28.765 D_real: 0.008 D_fake: 0.502 \n",
            "(epoch: 96, iters: 200, time: 0.089, data: 0.002) G_GAN: 4.539 G_L1: 31.028 D_real: 0.052 D_fake: 0.032 \n",
            "(epoch: 96, iters: 300, time: 0.092, data: 0.002) G_GAN: 1.484 G_L1: 17.087 D_real: 0.702 D_fake: 0.029 \n",
            "(epoch: 96, iters: 400, time: 0.366, data: 0.002) G_GAN: 5.183 G_L1: 17.414 D_real: 0.033 D_fake: 1.172 \n",
            "End of epoch 96 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.093, data: 0.156) G_GAN: 3.084 G_L1: 18.300 D_real: 0.065 D_fake: 0.268 \n",
            "(epoch: 97, iters: 200, time: 0.073, data: 0.002) G_GAN: 4.804 G_L1: 33.228 D_real: 0.158 D_fake: 0.041 \n",
            "(epoch: 97, iters: 300, time: 0.093, data: 0.003) G_GAN: 2.953 G_L1: 22.389 D_real: 0.029 D_fake: 0.150 \n",
            "(epoch: 97, iters: 400, time: 0.420, data: 0.002) G_GAN: 2.743 G_L1: 21.810 D_real: 0.083 D_fake: 0.054 \n",
            "End of epoch 97 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.092, data: 0.313) G_GAN: 3.817 G_L1: 24.023 D_real: 0.116 D_fake: 0.022 \n",
            "(epoch: 98, iters: 200, time: 0.074, data: 0.002) G_GAN: 4.921 G_L1: 20.680 D_real: 0.030 D_fake: 0.014 \n",
            "(epoch: 98, iters: 300, time: 0.093, data: 0.013) G_GAN: 0.745 G_L1: 23.985 D_real: 0.657 D_fake: 0.072 \n",
            "(epoch: 98, iters: 400, time: 0.601, data: 0.002) G_GAN: 2.992 G_L1: 27.278 D_real: 0.002 D_fake: 1.444 \n",
            "End of epoch 98 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.090, data: 0.174) G_GAN: 3.202 G_L1: 17.480 D_real: 0.084 D_fake: 0.107 \n",
            "(epoch: 99, iters: 200, time: 0.093, data: 0.002) G_GAN: 4.574 G_L1: 25.849 D_real: 0.021 D_fake: 1.194 \n",
            "(epoch: 99, iters: 300, time: 0.092, data: 0.002) G_GAN: 5.499 G_L1: 28.679 D_real: 0.001 D_fake: 1.966 \n",
            "(epoch: 99, iters: 400, time: 0.371, data: 0.002) G_GAN: 2.924 G_L1: 22.402 D_real: 0.010 D_fake: 0.300 \n",
            "End of epoch 99 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 100, time: 0.092, data: 0.162) G_GAN: 2.389 G_L1: 21.403 D_real: 0.050 D_fake: 0.093 \n",
            "(epoch: 100, iters: 200, time: 0.091, data: 0.002) G_GAN: 2.479 G_L1: 20.163 D_real: 0.178 D_fake: 0.291 \n",
            "(epoch: 100, iters: 300, time: 0.076, data: 0.002) G_GAN: 2.284 G_L1: 23.745 D_real: 0.245 D_fake: 0.284 \n",
            "(epoch: 100, iters: 400, time: 0.367, data: 0.010) G_GAN: 2.676 G_L1: 21.953 D_real: 0.104 D_fake: 0.162 \n",
            "saving the latest model (epoch 100, total_iters 40000)\n",
            "saving the model at the end of epoch 100, iters 40000\n",
            "End of epoch 100 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.093, data: 0.328) G_GAN: 3.122 G_L1: 20.058 D_real: 0.390 D_fake: 0.033 \n",
            "(epoch: 101, iters: 200, time: 0.089, data: 0.002) G_GAN: 3.459 G_L1: 26.496 D_real: 0.055 D_fake: 0.541 \n",
            "(epoch: 101, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.124 G_L1: 16.856 D_real: 0.083 D_fake: 0.300 \n",
            "(epoch: 101, iters: 400, time: 0.380, data: 0.002) G_GAN: 3.332 G_L1: 24.177 D_real: 0.022 D_fake: 0.436 \n",
            "End of epoch 101 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 100, time: 0.092, data: 0.138) G_GAN: 4.848 G_L1: 21.096 D_real: 0.385 D_fake: 0.007 \n",
            "(epoch: 102, iters: 200, time: 0.093, data: 0.002) G_GAN: 4.976 G_L1: 29.375 D_real: 0.046 D_fake: 0.022 \n",
            "(epoch: 102, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.732 G_L1: 25.152 D_real: 0.001 D_fake: 0.702 \n",
            "(epoch: 102, iters: 400, time: 0.374, data: 0.002) G_GAN: 1.885 G_L1: 16.966 D_real: 1.904 D_fake: 0.006 \n",
            "End of epoch 102 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 100, time: 0.088, data: 0.192) G_GAN: 4.312 G_L1: 30.508 D_real: 0.001 D_fake: 0.037 \n",
            "(epoch: 103, iters: 200, time: 0.093, data: 0.008) G_GAN: 2.288 G_L1: 18.811 D_real: 0.298 D_fake: 0.284 \n",
            "(epoch: 103, iters: 300, time: 0.071, data: 0.002) G_GAN: 3.484 G_L1: 20.075 D_real: 0.111 D_fake: 0.045 \n",
            "(epoch: 103, iters: 400, time: 0.388, data: 0.002) G_GAN: 3.993 G_L1: 28.607 D_real: 0.017 D_fake: 0.079 \n",
            "End of epoch 103 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 100, time: 0.091, data: 0.179) G_GAN: 1.215 G_L1: 18.148 D_real: 2.350 D_fake: 0.013 \n",
            "(epoch: 104, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.440 G_L1: 26.088 D_real: 0.038 D_fake: 0.052 \n",
            "(epoch: 104, iters: 300, time: 0.093, data: 0.002) G_GAN: 4.694 G_L1: 26.041 D_real: 0.001 D_fake: 0.055 \n",
            "(epoch: 104, iters: 400, time: 0.388, data: 0.002) G_GAN: 1.426 G_L1: 22.744 D_real: 0.580 D_fake: 0.141 \n",
            "End of epoch 104 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 100, time: 0.093, data: 0.144) G_GAN: 4.146 G_L1: 19.884 D_real: 0.412 D_fake: 0.017 \n",
            "(epoch: 105, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.424 G_L1: 21.695 D_real: 0.128 D_fake: 0.038 \n",
            "(epoch: 105, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.913 G_L1: 22.464 D_real: 0.093 D_fake: 0.321 \n",
            "(epoch: 105, iters: 400, time: 0.465, data: 0.002) G_GAN: 2.362 G_L1: 22.927 D_real: 0.021 D_fake: 0.410 \n",
            "saving the model at the end of epoch 105, iters 42000\n",
            "End of epoch 105 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 100, time: 0.093, data: 0.187) G_GAN: 4.863 G_L1: 25.041 D_real: 0.569 D_fake: 0.002 \n",
            "(epoch: 106, iters: 200, time: 0.074, data: 0.002) G_GAN: 4.272 G_L1: 19.541 D_real: 0.038 D_fake: 1.632 \n",
            "(epoch: 106, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.883 G_L1: 24.856 D_real: 0.030 D_fake: 0.040 \n",
            "(epoch: 106, iters: 400, time: 0.455, data: 0.002) G_GAN: 5.120 G_L1: 19.517 D_real: 0.011 D_fake: 1.395 \n",
            "End of epoch 106 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 100, time: 0.093, data: 0.287) G_GAN: 2.998 G_L1: 29.081 D_real: 0.003 D_fake: 0.320 \n",
            "(epoch: 107, iters: 200, time: 0.083, data: 0.002) G_GAN: 2.320 G_L1: 27.012 D_real: 0.353 D_fake: 0.070 \n",
            "(epoch: 107, iters: 300, time: 0.091, data: 0.002) G_GAN: 2.037 G_L1: 16.452 D_real: 0.844 D_fake: 0.029 \n",
            "(epoch: 107, iters: 400, time: 0.405, data: 0.002) G_GAN: 2.701 G_L1: 17.506 D_real: 0.144 D_fake: 0.066 \n",
            "End of epoch 107 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 100, time: 0.092, data: 0.180) G_GAN: 2.931 G_L1: 21.293 D_real: 0.157 D_fake: 0.116 \n",
            "(epoch: 108, iters: 200, time: 0.091, data: 0.002) G_GAN: 1.516 G_L1: 19.640 D_real: 0.372 D_fake: 0.131 \n",
            "(epoch: 108, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.634 G_L1: 17.544 D_real: 0.119 D_fake: 0.217 \n",
            "(epoch: 108, iters: 400, time: 0.628, data: 0.002) G_GAN: 3.899 G_L1: 26.089 D_real: 0.037 D_fake: 0.423 \n",
            "End of epoch 108 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 100, time: 0.091, data: 0.155) G_GAN: 3.403 G_L1: 22.084 D_real: 0.106 D_fake: 0.060 \n",
            "(epoch: 109, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.157 G_L1: 21.998 D_real: 0.275 D_fake: 0.040 \n",
            "(epoch: 109, iters: 300, time: 0.078, data: 0.002) G_GAN: 3.364 G_L1: 18.374 D_real: 0.131 D_fake: 0.055 \n",
            "(epoch: 109, iters: 400, time: 0.389, data: 0.008) G_GAN: 3.854 G_L1: 25.016 D_real: 0.010 D_fake: 0.165 \n",
            "End of epoch 109 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.083, data: 0.160) G_GAN: 5.053 G_L1: 20.004 D_real: 0.457 D_fake: 0.004 \n",
            "(epoch: 110, iters: 200, time: 0.093, data: 0.009) G_GAN: 3.078 G_L1: 21.940 D_real: 0.134 D_fake: 0.056 \n",
            "(epoch: 110, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.566 G_L1: 20.487 D_real: 0.296 D_fake: 0.085 \n",
            "(epoch: 110, iters: 400, time: 0.384, data: 0.002) G_GAN: 4.046 G_L1: 25.347 D_real: 0.115 D_fake: 0.033 \n",
            "saving the model at the end of epoch 110, iters 44000\n",
            "End of epoch 110 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 100, time: 0.093, data: 0.211) G_GAN: 3.000 G_L1: 16.774 D_real: 0.075 D_fake: 0.049 \n",
            "(epoch: 111, iters: 200, time: 0.092, data: 0.012) G_GAN: 2.155 G_L1: 17.961 D_real: 0.601 D_fake: 0.076 \n",
            "(epoch: 111, iters: 300, time: 0.090, data: 0.002) G_GAN: 2.450 G_L1: 19.949 D_real: 0.309 D_fake: 0.045 \n",
            "(epoch: 111, iters: 400, time: 0.393, data: 0.002) G_GAN: 3.352 G_L1: 36.083 D_real: 0.001 D_fake: 0.091 \n",
            "End of epoch 111 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 100, time: 0.092, data: 0.172) G_GAN: 2.865 G_L1: 26.211 D_real: 0.869 D_fake: 1.019 \n",
            "(epoch: 112, iters: 200, time: 0.092, data: 0.002) G_GAN: 5.498 G_L1: 18.692 D_real: 0.016 D_fake: 0.876 \n",
            "(epoch: 112, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.572 G_L1: 28.025 D_real: 0.070 D_fake: 0.043 \n",
            "(epoch: 112, iters: 400, time: 0.489, data: 0.002) G_GAN: 2.779 G_L1: 20.936 D_real: 0.126 D_fake: 0.168 \n",
            "End of epoch 112 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 100, time: 0.093, data: 0.226) G_GAN: 3.871 G_L1: 14.776 D_real: 0.168 D_fake: 0.018 \n",
            "(epoch: 113, iters: 200, time: 0.083, data: 0.002) G_GAN: 2.457 G_L1: 21.168 D_real: 0.342 D_fake: 0.041 \n",
            "saving the latest model (epoch 113, total_iters 45000)\n",
            "(epoch: 113, iters: 300, time: 0.091, data: 0.002) G_GAN: 2.937 G_L1: 26.130 D_real: 0.122 D_fake: 0.078 \n",
            "(epoch: 113, iters: 400, time: 0.460, data: 0.002) G_GAN: 4.022 G_L1: 22.441 D_real: 0.171 D_fake: 0.034 \n",
            "End of epoch 113 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 100, time: 0.092, data: 0.309) G_GAN: 4.871 G_L1: 20.981 D_real: 0.096 D_fake: 0.014 \n",
            "(epoch: 114, iters: 200, time: 0.082, data: 0.002) G_GAN: 3.119 G_L1: 19.038 D_real: 0.037 D_fake: 0.316 \n",
            "(epoch: 114, iters: 300, time: 0.092, data: 0.006) G_GAN: 3.272 G_L1: 18.444 D_real: 0.036 D_fake: 0.084 \n",
            "(epoch: 114, iters: 400, time: 0.404, data: 0.002) G_GAN: 2.282 G_L1: 21.131 D_real: 0.408 D_fake: 0.355 \n",
            "End of epoch 114 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 100, time: 0.093, data: 0.162) G_GAN: 3.998 G_L1: 26.660 D_real: 0.065 D_fake: 0.080 \n",
            "(epoch: 115, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.335 G_L1: 26.860 D_real: 0.560 D_fake: 0.105 \n",
            "(epoch: 115, iters: 300, time: 0.092, data: 0.002) G_GAN: 4.943 G_L1: 19.972 D_real: 0.059 D_fake: 0.564 \n",
            "(epoch: 115, iters: 400, time: 0.403, data: 0.002) G_GAN: 4.908 G_L1: 20.106 D_real: 0.050 D_fake: 0.021 \n",
            "saving the model at the end of epoch 115, iters 46000\n",
            "End of epoch 115 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 100, time: 0.092, data: 0.155) G_GAN: 3.418 G_L1: 28.324 D_real: 0.000 D_fake: 0.173 \n",
            "(epoch: 116, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.925 G_L1: 23.344 D_real: 0.177 D_fake: 0.101 \n",
            "(epoch: 116, iters: 300, time: 0.088, data: 0.002) G_GAN: 4.183 G_L1: 23.204 D_real: 0.364 D_fake: 0.023 \n",
            "(epoch: 116, iters: 400, time: 0.410, data: 0.002) G_GAN: 3.284 G_L1: 25.727 D_real: 0.089 D_fake: 0.148 \n",
            "End of epoch 116 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 100, time: 0.085, data: 0.168) G_GAN: 3.553 G_L1: 24.351 D_real: 0.030 D_fake: 0.229 \n",
            "(epoch: 117, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.897 G_L1: 19.719 D_real: 0.090 D_fake: 0.059 \n",
            "(epoch: 117, iters: 300, time: 0.075, data: 0.002) G_GAN: 2.522 G_L1: 20.554 D_real: 0.376 D_fake: 0.048 \n",
            "(epoch: 117, iters: 400, time: 0.646, data: 0.010) G_GAN: 2.295 G_L1: 19.313 D_real: 0.523 D_fake: 0.084 \n",
            "End of epoch 117 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 100, time: 0.090, data: 0.167) G_GAN: 3.208 G_L1: 16.180 D_real: 0.008 D_fake: 0.350 \n",
            "(epoch: 118, iters: 200, time: 0.094, data: 0.002) G_GAN: 3.432 G_L1: 17.759 D_real: 1.039 D_fake: 0.012 \n",
            "(epoch: 118, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.335 G_L1: 20.305 D_real: 0.017 D_fake: 0.189 \n",
            "(epoch: 118, iters: 400, time: 0.408, data: 0.002) G_GAN: 3.312 G_L1: 22.191 D_real: 0.046 D_fake: 0.106 \n",
            "End of epoch 118 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 100, time: 0.093, data: 0.171) G_GAN: 2.778 G_L1: 20.506 D_real: 0.137 D_fake: 0.051 \n",
            "(epoch: 119, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.738 G_L1: 21.592 D_real: 0.118 D_fake: 0.025 \n",
            "(epoch: 119, iters: 300, time: 0.092, data: 0.002) G_GAN: 5.231 G_L1: 19.201 D_real: 0.115 D_fake: 0.010 \n",
            "(epoch: 119, iters: 400, time: 0.499, data: 0.002) G_GAN: 4.291 G_L1: 32.300 D_real: 0.010 D_fake: 0.046 \n",
            "End of epoch 119 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 100, time: 0.092, data: 0.178) G_GAN: 3.236 G_L1: 21.515 D_real: 1.074 D_fake: 0.011 \n",
            "(epoch: 120, iters: 200, time: 0.076, data: 0.002) G_GAN: 3.268 G_L1: 23.678 D_real: 0.003 D_fake: 0.798 \n",
            "(epoch: 120, iters: 300, time: 0.094, data: 0.002) G_GAN: 2.337 G_L1: 29.776 D_real: 0.173 D_fake: 0.166 \n",
            "(epoch: 120, iters: 400, time: 0.477, data: 0.002) G_GAN: 2.398 G_L1: 20.179 D_real: 0.234 D_fake: 0.272 \n",
            "saving the model at the end of epoch 120, iters 48000\n",
            "End of epoch 120 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 100, time: 0.093, data: 0.188) G_GAN: 3.402 G_L1: 22.205 D_real: 0.235 D_fake: 0.025 \n",
            "(epoch: 121, iters: 200, time: 0.091, data: 0.002) G_GAN: 3.741 G_L1: 19.293 D_real: 0.417 D_fake: 0.022 \n",
            "(epoch: 121, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.583 G_L1: 21.157 D_real: 0.010 D_fake: 0.067 \n",
            "(epoch: 121, iters: 400, time: 0.420, data: 0.002) G_GAN: 4.005 G_L1: 24.660 D_real: 0.023 D_fake: 0.017 \n",
            "End of epoch 121 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 100, time: 0.089, data: 0.191) G_GAN: 2.861 G_L1: 22.139 D_real: 0.380 D_fake: 0.170 \n",
            "(epoch: 122, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.272 G_L1: 25.120 D_real: 0.238 D_fake: 0.216 \n",
            "(epoch: 122, iters: 300, time: 0.091, data: 0.002) G_GAN: 0.741 G_L1: 18.201 D_real: 1.384 D_fake: 0.017 \n",
            "(epoch: 122, iters: 400, time: 0.516, data: 0.002) G_GAN: 2.859 G_L1: 25.671 D_real: 0.024 D_fake: 0.196 \n",
            "End of epoch 122 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 100, time: 0.092, data: 0.228) G_GAN: 2.360 G_L1: 20.092 D_real: 0.223 D_fake: 0.085 \n",
            "(epoch: 123, iters: 200, time: 0.078, data: 0.002) G_GAN: 3.692 G_L1: 25.849 D_real: 0.294 D_fake: 0.034 \n",
            "(epoch: 123, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.790 G_L1: 24.114 D_real: 0.012 D_fake: 0.175 \n",
            "(epoch: 123, iters: 400, time: 0.423, data: 0.002) G_GAN: 5.167 G_L1: 20.999 D_real: 0.036 D_fake: 0.848 \n",
            "End of epoch 123 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 100, time: 0.093, data: 0.245) G_GAN: 1.358 G_L1: 16.637 D_real: 0.728 D_fake: 0.096 \n",
            "(epoch: 124, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.551 G_L1: 24.182 D_real: 0.136 D_fake: 0.053 \n",
            "(epoch: 124, iters: 300, time: 0.092, data: 0.002) G_GAN: 4.089 G_L1: 16.408 D_real: 0.081 D_fake: 0.038 \n",
            "(epoch: 124, iters: 400, time: 0.412, data: 0.002) G_GAN: 4.303 G_L1: 22.464 D_real: 0.164 D_fake: 0.035 \n",
            "End of epoch 124 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 100, time: 0.092, data: 0.175) G_GAN: 3.057 G_L1: 28.986 D_real: 0.012 D_fake: 0.286 \n",
            "(epoch: 125, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.284 G_L1: 30.266 D_real: 0.008 D_fake: 0.566 \n",
            "(epoch: 125, iters: 300, time: 0.072, data: 0.002) G_GAN: 3.139 G_L1: 25.110 D_real: 0.010 D_fake: 0.238 \n",
            "(epoch: 125, iters: 400, time: 0.424, data: 0.002) G_GAN: 1.540 G_L1: 20.267 D_real: 0.534 D_fake: 0.499 \n",
            "saving the latest model (epoch 125, total_iters 50000)\n",
            "saving the model at the end of epoch 125, iters 50000\n",
            "End of epoch 125 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 100, time: 0.093, data: 0.205) G_GAN: 1.994 G_L1: 23.670 D_real: 0.346 D_fake: 0.103 \n",
            "(epoch: 126, iters: 200, time: 0.084, data: 0.002) G_GAN: 3.276 G_L1: 19.569 D_real: 0.026 D_fake: 0.132 \n",
            "(epoch: 126, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.798 G_L1: 20.032 D_real: 0.019 D_fake: 0.032 \n",
            "(epoch: 126, iters: 400, time: 0.809, data: 0.002) G_GAN: 3.492 G_L1: 21.761 D_real: 0.103 D_fake: 0.038 \n",
            "End of epoch 126 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 100, time: 0.094, data: 0.265) G_GAN: 1.948 G_L1: 18.833 D_real: 1.006 D_fake: 0.033 \n",
            "(epoch: 127, iters: 200, time: 0.080, data: 0.002) G_GAN: 3.219 G_L1: 25.544 D_real: 0.101 D_fake: 0.146 \n",
            "(epoch: 127, iters: 300, time: 0.092, data: 0.003) G_GAN: 3.442 G_L1: 21.865 D_real: 0.232 D_fake: 0.380 \n",
            "(epoch: 127, iters: 400, time: 0.430, data: 0.002) G_GAN: 5.306 G_L1: 24.599 D_real: 0.027 D_fake: 0.008 \n",
            "End of epoch 127 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 100, time: 0.091, data: 0.238) G_GAN: 3.446 G_L1: 22.371 D_real: 0.023 D_fake: 0.416 \n",
            "(epoch: 128, iters: 200, time: 0.091, data: 0.002) G_GAN: 5.445 G_L1: 21.216 D_real: 0.314 D_fake: 0.004 \n",
            "(epoch: 128, iters: 300, time: 0.087, data: 0.002) G_GAN: 3.911 G_L1: 18.736 D_real: 0.135 D_fake: 0.110 \n",
            "(epoch: 128, iters: 400, time: 0.425, data: 0.002) G_GAN: 3.729 G_L1: 18.113 D_real: 0.077 D_fake: 0.029 \n",
            "End of epoch 128 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 100, time: 0.091, data: 0.153) G_GAN: 3.136 G_L1: 19.789 D_real: 0.404 D_fake: 0.023 \n",
            "(epoch: 129, iters: 200, time: 0.090, data: 0.002) G_GAN: 4.121 G_L1: 23.464 D_real: 0.042 D_fake: 0.045 \n",
            "(epoch: 129, iters: 300, time: 0.080, data: 0.002) G_GAN: 2.972 G_L1: 21.364 D_real: 0.007 D_fake: 0.214 \n",
            "(epoch: 129, iters: 400, time: 0.418, data: 0.002) G_GAN: 2.796 G_L1: 18.159 D_real: 0.117 D_fake: 0.322 \n",
            "End of epoch 129 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 100, time: 0.080, data: 0.147) G_GAN: 4.555 G_L1: 18.054 D_real: 0.443 D_fake: 0.005 \n",
            "(epoch: 130, iters: 200, time: 0.092, data: 0.005) G_GAN: 3.186 G_L1: 26.203 D_real: 0.003 D_fake: 0.046 \n",
            "(epoch: 130, iters: 300, time: 0.094, data: 0.002) G_GAN: 3.542 G_L1: 30.382 D_real: 0.910 D_fake: 0.031 \n",
            "(epoch: 130, iters: 400, time: 0.444, data: 0.002) G_GAN: 3.546 G_L1: 21.838 D_real: 0.020 D_fake: 0.143 \n",
            "saving the model at the end of epoch 130, iters 52000\n",
            "End of epoch 130 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 100, time: 0.094, data: 0.209) G_GAN: 2.704 G_L1: 22.826 D_real: 0.152 D_fake: 0.233 \n",
            "(epoch: 131, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.960 G_L1: 28.496 D_real: 0.004 D_fake: 0.116 \n",
            "(epoch: 131, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.180 G_L1: 21.034 D_real: 0.033 D_fake: 0.320 \n",
            "(epoch: 131, iters: 400, time: 0.437, data: 0.002) G_GAN: 3.140 G_L1: 16.752 D_real: 0.055 D_fake: 0.212 \n",
            "End of epoch 131 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 100, time: 0.093, data: 0.163) G_GAN: 4.775 G_L1: 34.021 D_real: 0.008 D_fake: 0.048 \n",
            "(epoch: 132, iters: 200, time: 0.090, data: 0.002) G_GAN: 2.473 G_L1: 22.272 D_real: 0.489 D_fake: 0.074 \n",
            "(epoch: 132, iters: 300, time: 0.091, data: 0.002) G_GAN: 4.703 G_L1: 24.413 D_real: 0.146 D_fake: 0.032 \n",
            "(epoch: 132, iters: 400, time: 0.538, data: 0.002) G_GAN: 2.018 G_L1: 18.460 D_real: 1.243 D_fake: 0.033 \n",
            "End of epoch 132 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 100, time: 0.092, data: 0.185) G_GAN: 3.145 G_L1: 22.582 D_real: 0.082 D_fake: 0.104 \n",
            "(epoch: 133, iters: 200, time: 0.082, data: 0.002) G_GAN: 3.071 G_L1: 16.883 D_real: 0.155 D_fake: 0.395 \n",
            "(epoch: 133, iters: 300, time: 0.093, data: 0.014) G_GAN: 2.932 G_L1: 16.005 D_real: 0.141 D_fake: 0.042 \n",
            "(epoch: 133, iters: 400, time: 0.492, data: 0.002) G_GAN: 4.496 G_L1: 22.093 D_real: 0.012 D_fake: 0.399 \n",
            "End of epoch 133 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 100, time: 0.092, data: 0.304) G_GAN: 3.459 G_L1: 32.355 D_real: 0.006 D_fake: 0.217 \n",
            "(epoch: 134, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.674 G_L1: 19.938 D_real: 0.011 D_fake: 0.172 \n",
            "(epoch: 134, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.173 G_L1: 20.035 D_real: 0.424 D_fake: 0.098 \n",
            "(epoch: 134, iters: 400, time: 0.677, data: 0.002) G_GAN: 3.382 G_L1: 22.751 D_real: 0.016 D_fake: 0.598 \n",
            "End of epoch 134 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 100, time: 0.091, data: 0.207) G_GAN: 3.040 G_L1: 20.397 D_real: 0.053 D_fake: 0.228 \n",
            "(epoch: 135, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.310 G_L1: 27.037 D_real: 0.159 D_fake: 0.051 \n",
            "(epoch: 135, iters: 300, time: 0.092, data: 0.002) G_GAN: 4.202 G_L1: 18.388 D_real: 0.005 D_fake: 1.210 \n",
            "(epoch: 135, iters: 400, time: 0.423, data: 0.002) G_GAN: 3.335 G_L1: 19.164 D_real: 0.022 D_fake: 0.307 \n",
            "saving the model at the end of epoch 135, iters 54000\n",
            "End of epoch 135 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 100, time: 0.089, data: 0.211) G_GAN: 4.830 G_L1: 24.423 D_real: 0.034 D_fake: 0.040 \n",
            "(epoch: 136, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.981 G_L1: 23.988 D_real: 0.013 D_fake: 0.274 \n",
            "(epoch: 136, iters: 300, time: 0.094, data: 0.002) G_GAN: 3.850 G_L1: 21.856 D_real: 0.170 D_fake: 0.042 \n",
            "(epoch: 136, iters: 400, time: 0.450, data: 0.002) G_GAN: 2.264 G_L1: 16.162 D_real: 0.286 D_fake: 0.134 \n",
            "End of epoch 136 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 100, time: 0.075, data: 0.152) G_GAN: 2.372 G_L1: 22.374 D_real: 0.689 D_fake: 0.031 \n",
            "(epoch: 137, iters: 200, time: 0.092, data: 0.003) G_GAN: 2.700 G_L1: 19.171 D_real: 0.037 D_fake: 0.175 \n",
            "(epoch: 137, iters: 300, time: 0.090, data: 0.002) G_GAN: 2.818 G_L1: 22.286 D_real: 0.001 D_fake: 0.340 \n",
            "(epoch: 137, iters: 400, time: 0.459, data: 0.002) G_GAN: 4.957 G_L1: 29.075 D_real: 0.025 D_fake: 0.036 \n",
            "End of epoch 137 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 100, time: 0.092, data: 0.157) G_GAN: 2.981 G_L1: 26.240 D_real: 0.052 D_fake: 0.215 \n",
            "(epoch: 138, iters: 200, time: 0.090, data: 0.002) G_GAN: 2.575 G_L1: 21.330 D_real: 0.148 D_fake: 0.074 \n",
            "saving the latest model (epoch 138, total_iters 55000)\n",
            "(epoch: 138, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.113 G_L1: 20.535 D_real: 0.238 D_fake: 0.042 \n",
            "(epoch: 138, iters: 400, time: 0.465, data: 0.002) G_GAN: 4.865 G_L1: 22.040 D_real: 0.006 D_fake: 0.815 \n",
            "End of epoch 138 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 100, time: 0.093, data: 0.246) G_GAN: 3.707 G_L1: 19.217 D_real: 0.020 D_fake: 0.086 \n",
            "(epoch: 139, iters: 200, time: 0.092, data: 0.002) G_GAN: 5.089 G_L1: 22.002 D_real: 0.012 D_fake: 0.013 \n",
            "(epoch: 139, iters: 300, time: 0.091, data: 0.002) G_GAN: 2.957 G_L1: 25.946 D_real: 0.453 D_fake: 0.052 \n",
            "(epoch: 139, iters: 400, time: 0.449, data: 0.002) G_GAN: 5.258 G_L1: 20.460 D_real: 0.029 D_fake: 0.017 \n",
            "End of epoch 139 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 100, time: 0.090, data: 0.218) G_GAN: 3.284 G_L1: 22.585 D_real: 0.253 D_fake: 0.034 \n",
            "(epoch: 140, iters: 200, time: 0.087, data: 0.002) G_GAN: 4.358 G_L1: 28.195 D_real: 0.036 D_fake: 0.025 \n",
            "(epoch: 140, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.860 G_L1: 24.719 D_real: 0.029 D_fake: 0.890 \n",
            "(epoch: 140, iters: 400, time: 0.511, data: 0.002) G_GAN: 3.654 G_L1: 25.021 D_real: 0.019 D_fake: 0.132 \n",
            "saving the model at the end of epoch 140, iters 56000\n",
            "End of epoch 140 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 0.092, data: 0.159) G_GAN: 2.717 G_L1: 19.753 D_real: 0.022 D_fake: 0.204 \n",
            "(epoch: 141, iters: 200, time: 0.085, data: 0.009) G_GAN: 4.285 G_L1: 21.630 D_real: 0.093 D_fake: 0.041 \n",
            "(epoch: 141, iters: 300, time: 0.091, data: 0.002) G_GAN: 3.583 G_L1: 18.224 D_real: 0.016 D_fake: 0.160 \n",
            "(epoch: 141, iters: 400, time: 0.539, data: 0.002) G_GAN: 2.397 G_L1: 15.959 D_real: 0.181 D_fake: 0.220 \n",
            "End of epoch 141 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 100, time: 0.092, data: 0.266) G_GAN: 4.881 G_L1: 20.385 D_real: 0.284 D_fake: 0.006 \n",
            "(epoch: 142, iters: 200, time: 0.089, data: 0.002) G_GAN: 4.327 G_L1: 18.472 D_real: 0.285 D_fake: 0.007 \n",
            "(epoch: 142, iters: 300, time: 0.092, data: 0.013) G_GAN: 3.528 G_L1: 18.415 D_real: 0.013 D_fake: 0.193 \n",
            "(epoch: 142, iters: 400, time: 0.696, data: 0.002) G_GAN: 5.458 G_L1: 24.365 D_real: 0.023 D_fake: 0.009 \n",
            "End of epoch 142 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 100, time: 0.092, data: 0.163) G_GAN: 2.836 G_L1: 23.584 D_real: 0.018 D_fake: 0.160 \n",
            "(epoch: 143, iters: 200, time: 0.092, data: 0.002) G_GAN: 4.152 G_L1: 21.733 D_real: 0.014 D_fake: 0.031 \n",
            "(epoch: 143, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.927 G_L1: 20.371 D_real: 0.012 D_fake: 0.099 \n",
            "(epoch: 143, iters: 400, time: 0.461, data: 0.002) G_GAN: 3.752 G_L1: 20.234 D_real: 0.059 D_fake: 0.055 \n",
            "End of epoch 143 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 100, time: 0.092, data: 0.173) G_GAN: 2.371 G_L1: 17.941 D_real: 0.602 D_fake: 0.028 \n",
            "(epoch: 144, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.128 G_L1: 15.656 D_real: 0.315 D_fake: 0.264 \n",
            "(epoch: 144, iters: 300, time: 0.082, data: 0.002) G_GAN: 3.911 G_L1: 15.608 D_real: 0.159 D_fake: 0.046 \n",
            "(epoch: 144, iters: 400, time: 0.452, data: 0.010) G_GAN: 3.647 G_L1: 19.414 D_real: 0.005 D_fake: 0.158 \n",
            "End of epoch 144 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 100, time: 0.083, data: 0.202) G_GAN: 2.646 G_L1: 18.391 D_real: 0.178 D_fake: 0.503 \n",
            "(epoch: 145, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.152 G_L1: 22.319 D_real: 0.139 D_fake: 0.174 \n",
            "(epoch: 145, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.018 G_L1: 25.229 D_real: 0.153 D_fake: 0.156 \n",
            "(epoch: 145, iters: 400, time: 0.467, data: 0.002) G_GAN: 4.195 G_L1: 24.674 D_real: 0.004 D_fake: 0.079 \n",
            "saving the model at the end of epoch 145, iters 58000\n",
            "End of epoch 145 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 100, time: 0.089, data: 0.177) G_GAN: 5.352 G_L1: 18.026 D_real: 0.117 D_fake: 0.009 \n",
            "(epoch: 146, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.897 G_L1: 15.103 D_real: 0.143 D_fake: 0.087 \n",
            "(epoch: 146, iters: 300, time: 0.090, data: 0.002) G_GAN: 2.698 G_L1: 26.945 D_real: 0.002 D_fake: 0.388 \n",
            "(epoch: 146, iters: 400, time: 0.470, data: 0.002) G_GAN: 3.194 G_L1: 21.506 D_real: 0.485 D_fake: 0.034 \n",
            "End of epoch 146 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 100, time: 0.093, data: 0.177) G_GAN: 5.107 G_L1: 17.821 D_real: 0.306 D_fake: 0.006 \n",
            "(epoch: 147, iters: 200, time: 0.093, data: 0.011) G_GAN: 5.609 G_L1: 17.414 D_real: 0.027 D_fake: 0.008 \n",
            "(epoch: 147, iters: 300, time: 0.094, data: 0.002) G_GAN: 4.165 G_L1: 27.982 D_real: 0.023 D_fake: 0.058 \n",
            "(epoch: 147, iters: 400, time: 0.571, data: 0.002) G_GAN: 2.914 G_L1: 20.254 D_real: 0.107 D_fake: 0.207 \n",
            "End of epoch 147 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 100, time: 0.092, data: 0.174) G_GAN: 2.645 G_L1: 17.883 D_real: 0.606 D_fake: 0.016 \n",
            "(epoch: 148, iters: 200, time: 0.077, data: 0.002) G_GAN: 4.873 G_L1: 22.807 D_real: 0.069 D_fake: 0.012 \n",
            "(epoch: 148, iters: 300, time: 0.093, data: 0.007) G_GAN: 4.335 G_L1: 14.040 D_real: 0.017 D_fake: 1.335 \n",
            "(epoch: 148, iters: 400, time: 0.503, data: 0.002) G_GAN: 3.164 G_L1: 22.265 D_real: 0.388 D_fake: 0.019 \n",
            "End of epoch 148 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 100, time: 0.092, data: 0.272) G_GAN: 3.073 G_L1: 20.236 D_real: 0.184 D_fake: 0.043 \n",
            "(epoch: 149, iters: 200, time: 0.077, data: 0.002) G_GAN: 2.907 G_L1: 15.075 D_real: 0.264 D_fake: 0.038 \n",
            "(epoch: 149, iters: 300, time: 0.091, data: 0.014) G_GAN: 3.511 G_L1: 21.150 D_real: 0.047 D_fake: 0.212 \n",
            "(epoch: 149, iters: 400, time: 0.700, data: 0.002) G_GAN: 3.322 G_L1: 19.071 D_real: 0.012 D_fake: 0.207 \n",
            "End of epoch 149 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 100, time: 0.093, data: 0.166) G_GAN: 3.417 G_L1: 19.411 D_real: 0.265 D_fake: 0.032 \n",
            "(epoch: 150, iters: 200, time: 0.091, data: 0.002) G_GAN: 3.397 G_L1: 29.143 D_real: 0.064 D_fake: 0.095 \n",
            "(epoch: 150, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.961 G_L1: 24.464 D_real: 0.066 D_fake: 0.032 \n",
            "(epoch: 150, iters: 400, time: 0.468, data: 0.002) G_GAN: 3.826 G_L1: 19.074 D_real: 0.012 D_fake: 0.055 \n",
            "saving the latest model (epoch 150, total_iters 60000)\n",
            "saving the model at the end of epoch 150, iters 60000\n",
            "End of epoch 150 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 100, time: 0.089, data: 0.201) G_GAN: 2.733 G_L1: 16.925 D_real: 0.151 D_fake: 0.093 \n",
            "(epoch: 151, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.288 G_L1: 18.728 D_real: 0.026 D_fake: 0.075 \n",
            "(epoch: 151, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.905 G_L1: 19.350 D_real: 0.056 D_fake: 0.093 \n",
            "(epoch: 151, iters: 400, time: 0.552, data: 0.002) G_GAN: 3.720 G_L1: 20.238 D_real: 0.394 D_fake: 0.027 \n",
            "End of epoch 151 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 100, time: 0.093, data: 0.158) G_GAN: 2.914 G_L1: 31.839 D_real: 0.006 D_fake: 0.161 \n",
            "(epoch: 152, iters: 200, time: 0.078, data: 0.002) G_GAN: 7.279 G_L1: 21.113 D_real: 0.006 D_fake: 0.002 \n",
            "(epoch: 152, iters: 300, time: 0.093, data: 0.014) G_GAN: 3.419 G_L1: 28.332 D_real: 0.044 D_fake: 0.389 \n",
            "(epoch: 152, iters: 400, time: 0.563, data: 0.002) G_GAN: 5.100 G_L1: 19.440 D_real: 0.228 D_fake: 0.011 \n",
            "End of epoch 152 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 100, time: 0.092, data: 0.323) G_GAN: 2.985 G_L1: 19.722 D_real: 0.231 D_fake: 0.036 \n",
            "(epoch: 153, iters: 200, time: 0.092, data: 0.002) G_GAN: 4.557 G_L1: 19.613 D_real: 0.082 D_fake: 0.017 \n",
            "(epoch: 153, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.768 G_L1: 22.684 D_real: 0.636 D_fake: 0.017 \n",
            "(epoch: 153, iters: 400, time: 0.483, data: 0.002) G_GAN: 3.282 G_L1: 19.946 D_real: 0.065 D_fake: 0.363 \n",
            "End of epoch 153 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 100, time: 0.092, data: 0.176) G_GAN: 3.511 G_L1: 21.810 D_real: 0.094 D_fake: 0.095 \n",
            "(epoch: 154, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.638 G_L1: 17.359 D_real: 0.060 D_fake: 0.055 \n",
            "(epoch: 154, iters: 300, time: 0.090, data: 0.002) G_GAN: 3.998 G_L1: 22.639 D_real: 0.101 D_fake: 0.014 \n",
            "(epoch: 154, iters: 400, time: 0.483, data: 0.002) G_GAN: 2.902 G_L1: 19.149 D_real: 0.125 D_fake: 0.239 \n",
            "End of epoch 154 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 100, time: 0.093, data: 0.163) G_GAN: 3.650 G_L1: 17.496 D_real: 0.070 D_fake: 0.075 \n",
            "(epoch: 155, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.558 G_L1: 13.385 D_real: 0.078 D_fake: 0.063 \n",
            "(epoch: 155, iters: 300, time: 0.083, data: 0.002) G_GAN: 3.600 G_L1: 25.325 D_real: 0.026 D_fake: 0.077 \n",
            "(epoch: 155, iters: 400, time: 0.485, data: 0.012) G_GAN: 2.588 G_L1: 22.914 D_real: 0.217 D_fake: 0.080 \n",
            "saving the model at the end of epoch 155, iters 62000\n",
            "End of epoch 155 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 100, time: 0.091, data: 0.202) G_GAN: 3.198 G_L1: 19.729 D_real: 0.281 D_fake: 0.019 \n",
            "(epoch: 156, iters: 200, time: 0.082, data: 0.002) G_GAN: 2.786 G_L1: 17.891 D_real: 0.179 D_fake: 0.046 \n",
            "(epoch: 156, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.822 G_L1: 26.183 D_real: 0.006 D_fake: 0.079 \n",
            "(epoch: 156, iters: 400, time: 0.886, data: 0.002) G_GAN: 4.364 G_L1: 22.467 D_real: 0.135 D_fake: 0.018 \n",
            "End of epoch 156 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 100, time: 0.094, data: 0.277) G_GAN: 3.110 G_L1: 19.953 D_real: 0.002 D_fake: 0.153 \n",
            "(epoch: 157, iters: 200, time: 0.082, data: 0.002) G_GAN: 5.159 G_L1: 22.096 D_real: 0.345 D_fake: 0.013 \n",
            "(epoch: 157, iters: 300, time: 0.094, data: 0.010) G_GAN: 4.403 G_L1: 16.776 D_real: 0.012 D_fake: 0.500 \n",
            "(epoch: 157, iters: 400, time: 0.484, data: 0.002) G_GAN: 6.365 G_L1: 21.620 D_real: 0.106 D_fake: 0.003 \n",
            "End of epoch 157 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 100, time: 0.092, data: 0.168) G_GAN: 3.218 G_L1: 16.924 D_real: 0.106 D_fake: 0.087 \n",
            "(epoch: 158, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.766 G_L1: 18.209 D_real: 0.153 D_fake: 0.071 \n",
            "(epoch: 158, iters: 300, time: 0.086, data: 0.002) G_GAN: 2.891 G_L1: 16.373 D_real: 0.415 D_fake: 0.042 \n",
            "(epoch: 158, iters: 400, time: 0.501, data: 0.002) G_GAN: 3.650 G_L1: 24.830 D_real: 0.005 D_fake: 0.057 \n",
            "End of epoch 158 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 100, time: 0.093, data: 0.152) G_GAN: 2.337 G_L1: 16.260 D_real: 2.002 D_fake: 0.004 \n",
            "(epoch: 159, iters: 200, time: 0.094, data: 0.002) G_GAN: 3.062 G_L1: 28.390 D_real: 0.128 D_fake: 0.144 \n",
            "(epoch: 159, iters: 300, time: 0.083, data: 0.002) G_GAN: 4.290 G_L1: 25.008 D_real: 0.110 D_fake: 0.030 \n",
            "(epoch: 159, iters: 400, time: 0.487, data: 0.008) G_GAN: 5.452 G_L1: 22.658 D_real: 0.170 D_fake: 0.008 \n",
            "End of epoch 159 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 0.078, data: 0.153) G_GAN: 2.715 G_L1: 14.550 D_real: 0.063 D_fake: 0.334 \n",
            "(epoch: 160, iters: 200, time: 0.093, data: 0.009) G_GAN: 3.150 G_L1: 16.077 D_real: 0.015 D_fake: 0.397 \n",
            "(epoch: 160, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.890 G_L1: 27.699 D_real: 0.471 D_fake: 0.012 \n",
            "(epoch: 160, iters: 400, time: 0.500, data: 0.002) G_GAN: 2.821 G_L1: 22.195 D_real: 0.409 D_fake: 0.077 \n",
            "saving the model at the end of epoch 160, iters 64000\n",
            "End of epoch 160 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 100, time: 0.076, data: 0.182) G_GAN: 5.246 G_L1: 15.915 D_real: 0.194 D_fake: 0.025 \n",
            "(epoch: 161, iters: 200, time: 0.094, data: 0.012) G_GAN: 3.018 G_L1: 23.955 D_real: 0.073 D_fake: 0.249 \n",
            "(epoch: 161, iters: 300, time: 0.094, data: 0.002) G_GAN: 2.483 G_L1: 20.908 D_real: 0.188 D_fake: 0.095 \n",
            "(epoch: 161, iters: 400, time: 0.491, data: 0.002) G_GAN: 4.241 G_L1: 20.785 D_real: 0.101 D_fake: 0.023 \n",
            "End of epoch 161 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 100, time: 0.092, data: 0.176) G_GAN: 4.139 G_L1: 22.693 D_real: 0.001 D_fake: 0.085 \n",
            "(epoch: 162, iters: 200, time: 0.092, data: 0.003) G_GAN: 3.378 G_L1: 25.893 D_real: 0.022 D_fake: 0.082 \n",
            "(epoch: 162, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.447 G_L1: 21.354 D_real: 0.001 D_fake: 0.129 \n",
            "(epoch: 162, iters: 400, time: 0.754, data: 0.002) G_GAN: 3.645 G_L1: 13.383 D_real: 0.010 D_fake: 0.071 \n",
            "End of epoch 162 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 100, time: 0.091, data: 0.187) G_GAN: 3.218 G_L1: 19.834 D_real: 0.037 D_fake: 0.087 \n",
            "(epoch: 163, iters: 200, time: 0.075, data: 0.002) G_GAN: 4.551 G_L1: 18.689 D_real: 0.082 D_fake: 0.020 \n",
            "saving the latest model (epoch 163, total_iters 65000)\n",
            "(epoch: 163, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.581 G_L1: 17.633 D_real: 0.063 D_fake: 0.286 \n",
            "(epoch: 163, iters: 400, time: 0.619, data: 0.002) G_GAN: 2.383 G_L1: 19.214 D_real: 0.070 D_fake: 0.148 \n",
            "End of epoch 163 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 100, time: 0.091, data: 0.177) G_GAN: 4.107 G_L1: 22.222 D_real: 0.010 D_fake: 0.046 \n",
            "(epoch: 164, iters: 200, time: 0.083, data: 0.002) G_GAN: 4.228 G_L1: 21.768 D_real: 0.057 D_fake: 0.027 \n",
            "(epoch: 164, iters: 300, time: 0.093, data: 0.012) G_GAN: 5.385 G_L1: 36.028 D_real: 0.003 D_fake: 0.938 \n",
            "(epoch: 164, iters: 400, time: 0.554, data: 0.002) G_GAN: 4.154 G_L1: 21.352 D_real: 0.014 D_fake: 0.036 \n",
            "End of epoch 164 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 100, time: 0.093, data: 0.258) G_GAN: 4.659 G_L1: 31.766 D_real: 0.032 D_fake: 0.026 \n",
            "(epoch: 165, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.126 G_L1: 12.526 D_real: 0.058 D_fake: 0.117 \n",
            "(epoch: 165, iters: 300, time: 0.094, data: 0.001) G_GAN: 3.160 G_L1: 19.648 D_real: 0.304 D_fake: 0.025 \n",
            "(epoch: 165, iters: 400, time: 0.485, data: 0.002) G_GAN: 1.608 G_L1: 24.301 D_real: 0.772 D_fake: 0.124 \n",
            "saving the model at the end of epoch 165, iters 66000\n",
            "End of epoch 165 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 0.094, data: 0.380) G_GAN: 3.113 G_L1: 21.267 D_real: 0.068 D_fake: 0.231 \n",
            "(epoch: 166, iters: 200, time: 0.091, data: 0.002) G_GAN: 3.316 G_L1: 17.250 D_real: 0.064 D_fake: 0.072 \n",
            "(epoch: 166, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.413 G_L1: 17.049 D_real: 0.300 D_fake: 0.107 \n",
            "(epoch: 166, iters: 400, time: 0.507, data: 0.002) G_GAN: 3.619 G_L1: 20.184 D_real: 0.057 D_fake: 0.124 \n",
            "End of epoch 166 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 100, time: 0.093, data: 0.163) G_GAN: 4.265 G_L1: 16.852 D_real: 0.337 D_fake: 0.012 \n",
            "(epoch: 167, iters: 200, time: 0.094, data: 0.002) G_GAN: 2.664 G_L1: 17.924 D_real: 0.008 D_fake: 0.253 \n",
            "(epoch: 167, iters: 300, time: 0.094, data: 0.002) G_GAN: 1.794 G_L1: 17.763 D_real: 0.117 D_fake: 0.508 \n",
            "(epoch: 167, iters: 400, time: 0.509, data: 0.002) G_GAN: 3.234 G_L1: 23.991 D_real: 0.001 D_fake: 0.410 \n",
            "End of epoch 167 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 100, time: 0.078, data: 0.156) G_GAN: 3.935 G_L1: 18.275 D_real: 0.035 D_fake: 0.035 \n",
            "(epoch: 168, iters: 200, time: 0.093, data: 0.009) G_GAN: 4.159 G_L1: 15.791 D_real: 0.584 D_fake: 0.004 \n",
            "(epoch: 168, iters: 300, time: 0.090, data: 0.002) G_GAN: 3.397 G_L1: 23.674 D_real: 0.056 D_fake: 0.084 \n",
            "(epoch: 168, iters: 400, time: 0.511, data: 0.010) G_GAN: 3.892 G_L1: 22.740 D_real: 0.088 D_fake: 0.034 \n",
            "End of epoch 168 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 100, time: 0.092, data: 0.164) G_GAN: 5.915 G_L1: 20.556 D_real: 0.031 D_fake: 0.010 \n",
            "(epoch: 169, iters: 200, time: 0.091, data: 0.002) G_GAN: 2.874 G_L1: 21.482 D_real: 0.611 D_fake: 0.026 \n",
            "(epoch: 169, iters: 300, time: 0.094, data: 0.002) G_GAN: 4.632 G_L1: 22.781 D_real: 0.342 D_fake: 0.009 \n",
            "(epoch: 169, iters: 400, time: 0.734, data: 0.002) G_GAN: 3.237 G_L1: 25.003 D_real: 0.243 D_fake: 0.047 \n",
            "End of epoch 169 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 100, time: 0.094, data: 0.191) G_GAN: 3.497 G_L1: 17.109 D_real: 0.031 D_fake: 0.118 \n",
            "(epoch: 170, iters: 200, time: 0.093, data: 0.001) G_GAN: 3.964 G_L1: 18.970 D_real: 0.186 D_fake: 0.024 \n",
            "(epoch: 170, iters: 300, time: 0.093, data: 0.001) G_GAN: 2.961 G_L1: 19.741 D_real: 0.168 D_fake: 0.095 \n",
            "(epoch: 170, iters: 400, time: 0.512, data: 0.002) G_GAN: 3.142 G_L1: 17.831 D_real: 0.112 D_fake: 0.232 \n",
            "saving the model at the end of epoch 170, iters 68000\n",
            "End of epoch 170 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 100, time: 0.093, data: 0.167) G_GAN: 3.441 G_L1: 20.609 D_real: 0.023 D_fake: 0.087 \n",
            "(epoch: 171, iters: 200, time: 0.094, data: 0.002) G_GAN: 3.590 G_L1: 20.578 D_real: 0.036 D_fake: 0.077 \n",
            "(epoch: 171, iters: 300, time: 0.093, data: 0.003) G_GAN: 2.472 G_L1: 15.344 D_real: 0.291 D_fake: 0.078 \n",
            "(epoch: 171, iters: 400, time: 0.608, data: 0.001) G_GAN: 4.479 G_L1: 26.047 D_real: 0.010 D_fake: 0.024 \n",
            "End of epoch 171 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 100, time: 0.091, data: 0.175) G_GAN: 3.541 G_L1: 18.511 D_real: 0.006 D_fake: 0.096 \n",
            "(epoch: 172, iters: 200, time: 0.079, data: 0.001) G_GAN: 4.347 G_L1: 21.526 D_real: 0.096 D_fake: 0.019 \n",
            "(epoch: 172, iters: 300, time: 0.094, data: 0.014) G_GAN: 3.559 G_L1: 20.652 D_real: 0.108 D_fake: 0.076 \n",
            "(epoch: 172, iters: 400, time: 0.604, data: 0.002) G_GAN: 4.422 G_L1: 18.340 D_real: 0.030 D_fake: 0.028 \n",
            "End of epoch 172 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 100, time: 0.092, data: 0.276) G_GAN: 2.390 G_L1: 23.545 D_real: 0.174 D_fake: 0.200 \n",
            "(epoch: 173, iters: 200, time: 0.093, data: 0.001) G_GAN: 3.427 G_L1: 24.771 D_real: 0.000 D_fake: 0.421 \n",
            "(epoch: 173, iters: 300, time: 0.092, data: 0.002) G_GAN: 3.135 G_L1: 18.214 D_real: 0.345 D_fake: 0.029 \n",
            "(epoch: 173, iters: 400, time: 0.528, data: 0.001) G_GAN: 4.889 G_L1: 16.994 D_real: 0.026 D_fake: 0.954 \n",
            "End of epoch 173 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 100, time: 0.085, data: 0.171) G_GAN: 1.778 G_L1: 17.591 D_real: 1.253 D_fake: 0.053 \n",
            "(epoch: 174, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.860 G_L1: 21.046 D_real: 0.406 D_fake: 0.029 \n",
            "(epoch: 174, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.516 G_L1: 21.869 D_real: 0.028 D_fake: 0.068 \n",
            "(epoch: 174, iters: 400, time: 0.518, data: 0.002) G_GAN: 2.977 G_L1: 19.834 D_real: 0.182 D_fake: 0.074 \n",
            "End of epoch 174 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 100, time: 0.080, data: 0.176) G_GAN: 3.818 G_L1: 21.890 D_real: 0.041 D_fake: 0.038 \n",
            "(epoch: 175, iters: 200, time: 0.093, data: 0.009) G_GAN: 2.331 G_L1: 23.691 D_real: 0.297 D_fake: 0.111 \n",
            "(epoch: 175, iters: 300, time: 0.079, data: 0.002) G_GAN: 2.257 G_L1: 16.231 D_real: 0.234 D_fake: 0.354 \n",
            "(epoch: 175, iters: 400, time: 0.751, data: 0.001) G_GAN: 3.409 G_L1: 14.900 D_real: 0.504 D_fake: 0.013 \n",
            "saving the latest model (epoch 175, total_iters 70000)\n",
            "saving the model at the end of epoch 175, iters 70000\n",
            "End of epoch 175 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 100, time: 0.093, data: 0.360) G_GAN: 3.050 G_L1: 25.205 D_real: 0.025 D_fake: 0.201 \n",
            "(epoch: 176, iters: 200, time: 0.092, data: 0.001) G_GAN: 3.422 G_L1: 23.706 D_real: 0.003 D_fake: 0.110 \n",
            "(epoch: 176, iters: 300, time: 0.090, data: 0.002) G_GAN: 3.249 G_L1: 16.036 D_real: 0.006 D_fake: 0.109 \n",
            "(epoch: 176, iters: 400, time: 0.518, data: 0.002) G_GAN: 5.272 G_L1: 20.725 D_real: 0.054 D_fake: 0.009 \n",
            "End of epoch 176 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 100, time: 0.094, data: 0.151) G_GAN: 3.685 G_L1: 21.404 D_real: 0.026 D_fake: 0.087 \n",
            "(epoch: 177, iters: 200, time: 0.092, data: 0.002) G_GAN: 3.051 G_L1: 22.539 D_real: 0.021 D_fake: 0.147 \n",
            "(epoch: 177, iters: 300, time: 0.094, data: 0.002) G_GAN: 5.109 G_L1: 23.547 D_real: 0.006 D_fake: 0.019 \n",
            "(epoch: 177, iters: 400, time: 0.521, data: 0.002) G_GAN: 2.912 G_L1: 21.360 D_real: 0.014 D_fake: 0.454 \n",
            "End of epoch 177 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 100, time: 0.092, data: 0.154) G_GAN: 3.381 G_L1: 19.444 D_real: 0.157 D_fake: 0.861 \n",
            "(epoch: 178, iters: 200, time: 0.093, data: 0.002) G_GAN: 2.962 G_L1: 20.203 D_real: 0.182 D_fake: 0.092 \n",
            "(epoch: 178, iters: 300, time: 0.089, data: 0.002) G_GAN: 4.812 G_L1: 17.675 D_real: 0.014 D_fake: 0.019 \n",
            "(epoch: 178, iters: 400, time: 0.523, data: 0.002) G_GAN: 4.183 G_L1: 27.733 D_real: 0.018 D_fake: 0.036 \n",
            "End of epoch 178 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 100, time: 0.083, data: 0.177) G_GAN: 2.775 G_L1: 17.414 D_real: 0.086 D_fake: 0.118 \n",
            "(epoch: 179, iters: 200, time: 0.090, data: 0.010) G_GAN: 2.779 G_L1: 26.623 D_real: 0.250 D_fake: 0.113 \n",
            "(epoch: 179, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.955 G_L1: 18.839 D_real: 0.008 D_fake: 0.174 \n",
            "(epoch: 179, iters: 400, time: 0.527, data: 0.002) G_GAN: 4.127 G_L1: 20.205 D_real: 0.219 D_fake: 0.018 \n",
            "End of epoch 179 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 100, time: 0.094, data: 0.189) G_GAN: 3.285 G_L1: 19.044 D_real: 0.197 D_fake: 0.049 \n",
            "(epoch: 180, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.594 G_L1: 16.572 D_real: 0.095 D_fake: 0.180 \n",
            "(epoch: 180, iters: 300, time: 0.094, data: 0.002) G_GAN: 3.884 G_L1: 21.281 D_real: 0.099 D_fake: 0.053 \n",
            "(epoch: 180, iters: 400, time: 0.517, data: 0.001) G_GAN: 3.952 G_L1: 18.083 D_real: 0.201 D_fake: 0.026 \n",
            "saving the model at the end of epoch 180, iters 72000\n",
            "End of epoch 180 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 100, time: 0.091, data: 0.168) G_GAN: 3.564 G_L1: 19.226 D_real: 0.051 D_fake: 0.060 \n",
            "(epoch: 181, iters: 200, time: 0.090, data: 0.002) G_GAN: 3.657 G_L1: 17.303 D_real: 0.002 D_fake: 0.077 \n",
            "(epoch: 181, iters: 300, time: 0.084, data: 0.002) G_GAN: 4.895 G_L1: 19.653 D_real: 0.120 D_fake: 0.014 \n",
            "(epoch: 181, iters: 400, time: 0.795, data: 0.008) G_GAN: 2.776 G_L1: 24.605 D_real: 0.033 D_fake: 0.221 \n",
            "End of epoch 181 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 100, time: 0.087, data: 0.166) G_GAN: 3.090 G_L1: 19.304 D_real: 0.059 D_fake: 0.079 \n",
            "(epoch: 182, iters: 200, time: 0.089, data: 0.002) G_GAN: 4.159 G_L1: 24.785 D_real: 0.039 D_fake: 0.038 \n",
            "(epoch: 182, iters: 300, time: 0.079, data: 0.002) G_GAN: 4.133 G_L1: 23.615 D_real: 0.014 D_fake: 0.035 \n",
            "(epoch: 182, iters: 400, time: 0.539, data: 0.008) G_GAN: 3.870 G_L1: 18.960 D_real: 0.339 D_fake: 0.029 \n",
            "End of epoch 182 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 100, time: 0.093, data: 0.175) G_GAN: 3.082 G_L1: 18.522 D_real: 0.145 D_fake: 0.085 \n",
            "(epoch: 183, iters: 200, time: 0.094, data: 0.001) G_GAN: 5.578 G_L1: 17.529 D_real: 0.006 D_fake: 0.010 \n",
            "(epoch: 183, iters: 300, time: 0.092, data: 0.002) G_GAN: 2.985 G_L1: 29.111 D_real: 0.035 D_fake: 0.123 \n",
            "(epoch: 183, iters: 400, time: 0.517, data: 0.002) G_GAN: 2.990 G_L1: 18.152 D_real: 0.031 D_fake: 0.106 \n",
            "End of epoch 183 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 100, time: 0.092, data: 0.173) G_GAN: 3.117 G_L1: 29.883 D_real: 0.000 D_fake: 0.128 \n",
            "(epoch: 184, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.151 G_L1: 24.521 D_real: 0.042 D_fake: 0.116 \n",
            "(epoch: 184, iters: 300, time: 0.090, data: 0.002) G_GAN: 3.357 G_L1: 17.507 D_real: 0.133 D_fake: 0.085 \n",
            "(epoch: 184, iters: 400, time: 0.658, data: 0.002) G_GAN: 4.486 G_L1: 22.701 D_real: 0.049 D_fake: 0.024 \n",
            "End of epoch 184 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 100, time: 0.093, data: 0.235) G_GAN: 4.107 G_L1: 17.731 D_real: 0.111 D_fake: 0.034 \n",
            "(epoch: 185, iters: 200, time: 0.082, data: 0.002) G_GAN: 3.383 G_L1: 24.457 D_real: 0.123 D_fake: 0.060 \n",
            "(epoch: 185, iters: 300, time: 0.093, data: 0.010) G_GAN: 3.641 G_L1: 31.081 D_real: 0.053 D_fake: 0.150 \n",
            "(epoch: 185, iters: 400, time: 0.543, data: 0.002) G_GAN: 2.230 G_L1: 14.341 D_real: 0.152 D_fake: 0.225 \n",
            "saving the model at the end of epoch 185, iters 74000\n",
            "End of epoch 185 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 100, time: 0.091, data: 0.175) G_GAN: 3.371 G_L1: 17.774 D_real: 0.069 D_fake: 0.072 \n",
            "(epoch: 186, iters: 200, time: 0.091, data: 0.002) G_GAN: 5.000 G_L1: 25.743 D_real: 0.037 D_fake: 0.013 \n",
            "(epoch: 186, iters: 300, time: 0.094, data: 0.002) G_GAN: 3.720 G_L1: 14.752 D_real: 0.044 D_fake: 0.053 \n",
            "(epoch: 186, iters: 400, time: 0.562, data: 0.002) G_GAN: 2.639 G_L1: 16.695 D_real: 0.096 D_fake: 0.129 \n",
            "End of epoch 186 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 100, time: 0.093, data: 0.149) G_GAN: 2.598 G_L1: 25.003 D_real: 0.257 D_fake: 0.141 \n",
            "(epoch: 187, iters: 200, time: 0.083, data: 0.002) G_GAN: 2.933 G_L1: 31.261 D_real: 0.007 D_fake: 0.143 \n",
            "(epoch: 187, iters: 300, time: 0.092, data: 0.006) G_GAN: 4.846 G_L1: 27.759 D_real: 0.007 D_fake: 0.019 \n",
            "(epoch: 187, iters: 400, time: 0.976, data: 0.002) G_GAN: 3.297 G_L1: 26.587 D_real: 0.038 D_fake: 0.096 \n",
            "End of epoch 187 / 200 \t Time Taken: 23 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 100, time: 0.093, data: 0.344) G_GAN: 3.391 G_L1: 17.866 D_real: 0.077 D_fake: 0.082 \n",
            "(epoch: 188, iters: 200, time: 0.075, data: 0.002) G_GAN: 3.054 G_L1: 26.042 D_real: 0.002 D_fake: 0.157 \n",
            "saving the latest model (epoch 188, total_iters 75000)\n",
            "(epoch: 188, iters: 300, time: 0.092, data: 0.009) G_GAN: 3.365 G_L1: 15.437 D_real: 0.135 D_fake: 0.049 \n",
            "(epoch: 188, iters: 400, time: 0.648, data: 0.002) G_GAN: 2.896 G_L1: 19.013 D_real: 0.506 D_fake: 0.045 \n",
            "End of epoch 188 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 100, time: 0.092, data: 0.275) G_GAN: 4.872 G_L1: 19.346 D_real: 0.013 D_fake: 0.014 \n",
            "(epoch: 189, iters: 200, time: 0.089, data: 0.002) G_GAN: 3.986 G_L1: 18.697 D_real: 0.104 D_fake: 0.039 \n",
            "(epoch: 189, iters: 300, time: 0.090, data: 0.005) G_GAN: 4.278 G_L1: 23.377 D_real: 0.103 D_fake: 0.025 \n",
            "(epoch: 189, iters: 400, time: 0.548, data: 0.002) G_GAN: 3.661 G_L1: 26.801 D_real: 0.005 D_fake: 0.055 \n",
            "End of epoch 189 / 200 \t Time Taken: 22 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 100, time: 0.092, data: 0.141) G_GAN: 3.045 G_L1: 20.604 D_real: 0.048 D_fake: 0.132 \n",
            "(epoch: 190, iters: 200, time: 0.093, data: 0.002) G_GAN: 3.672 G_L1: 18.012 D_real: 0.109 D_fake: 0.049 \n",
            "(epoch: 190, iters: 300, time: 0.093, data: 0.002) G_GAN: 2.295 G_L1: 17.384 D_real: 0.016 D_fake: 0.417 \n",
            "(epoch: 190, iters: 400, time: 0.557, data: 0.002) G_GAN: 4.329 G_L1: 19.891 D_real: 0.064 D_fake: 0.029 \n",
            "saving the model at the end of epoch 190, iters 76000\n",
            "End of epoch 190 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 0.095, data: 0.211) G_GAN: 4.009 G_L1: 18.340 D_real: 0.044 D_fake: 0.031 \n",
            "(epoch: 191, iters: 200, time: 0.092, data: 0.002) G_GAN: 2.783 G_L1: 24.707 D_real: 0.136 D_fake: 0.115 \n",
            "(epoch: 191, iters: 300, time: 0.093, data: 0.002) G_GAN: 3.496 G_L1: 22.986 D_real: 0.007 D_fake: 0.068 \n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA --display_id -1 --n_epoch 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
        "\n",
        "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
        "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
        "\n",
        "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
        "\n",
        "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mey7o6j-0368"
      },
      "outputs": [],
      "source": [
        "!ls checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCsKkEq0yGh0"
      },
      "outputs": [],
      "source": [
        "!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_label2photo_pretrained --use_wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSKIPUByfiN"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mgg8raPyizq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G3oVH9DyqLQ"
      },
      "outputs": [],
      "source": [
        "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErK5OC1j1LH4"
      },
      "outputs": [],
      "source": [
        "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
        "plt.imshow(img)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pix2pix",
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "name": "tf2-gpu.2-3.m74",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}